[
  {
    "title": "Opening the black box of deep learning",
    "text": "Opening the black box of deep learning. The great success of deep learning shows that its technology contains\nprofound truth, and understanding its internal mechanism not only has important\nimplications for the development of its technology and effective application in\nvarious fields, but also provides meaningful insights into the understanding of\nhuman brain mechanism. At present, most of the theoretical research on deep\nlearning is based on mathematics. This dissertation proposes that the neural\nnetwork of deep learning is a physical system, examines deep learning from\nthree different perspectives: microscopic, macroscopic, and physical world\nviews, answers multiple theoretical puzzles in deep learning by using physics\nprinciples. For example, from the perspective of quantum mechanics and\nstatistical physics, this dissertation presents the calculation methods for\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\nMachine, as well as the selection of cost functions, explains why deep learning\nmust be deep, what characteristics are learned in deep learning, why\nConvolutional Neural Networks do not have to be trained layer by layer, and the\nlimitations of deep learning, etc., and proposes the theoretical direction and\nbasis for the further development of deep learning now and in the future. The\nbrilliance of physics flashes in deep learning, we try to establish the deep\nlearning technology based on the scientific theory of physics.",
    "pdf_link": "http://arxiv.org/pdf/1805.08355v1.pdf",
    "authors": [
      "Dian Lei",
      "Xiaoxiao Chen",
      "Jianfei Zhao"
    ]
  },
  {
    "title": "Deep learning research landscape & roadmap in a nutshell: past, present\n  and future -- Towards deep cortical learning",
    "text": "Deep learning research landscape & roadmap in a nutshell: past, present\n  and future -- Towards deep cortical learning. The past, present and future of deep learning is presented in this work.\nGiven this landscape & roadmap, we predict that deep cortical learning will be\nthe convergence of deep learning & cortical learning which builds an artificial\ncortical column ultimately.",
    "pdf_link": "http://arxiv.org/pdf/1908.02130v1.pdf",
    "authors": [
      "Aras R. Dargazany"
    ]
  },
  {
    "title": "Concept-Oriented Deep Learning",
    "text": "Concept-Oriented Deep Learning. Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.",
    "pdf_link": "http://arxiv.org/pdf/1806.01756v1.pdf",
    "authors": [
      "Daniel T Chang"
    ]
  },
  {
    "title": "A First Look at Deep Learning Apps on Smartphones",
    "text": "A First Look at Deep Learning Apps on Smartphones. We are in the dawn of deep learning explosion for smartphones. To bridge the\ngap between research and practice, we present the first empirical study on\n16,500 the most popular Android apps, demystifying how smartphone apps exploit\ndeep learning in the wild. To this end, we build a new static tool that\ndissects apps and analyzes their deep learning functions. Our study answers\nthreefold questions: what are the early adopter apps of deep learning, what do\nthey use deep learning for, and how do their deep learning models look like.\nOur study has strong implications for app developers, smartphone vendors, and\ndeep learning R\\&D. On one hand, our findings paint a promising picture of deep\nlearning for smartphones, showing the prosperity of mobile deep learning\nframeworks as well as the prosperity of apps building their cores atop deep\nlearning. On the other hand, our findings urge optimizations on deep learning\nmodels deployed on smartphones, the protection of these models, and validation\nof research ideas on these models.",
    "pdf_link": "http://arxiv.org/pdf/1812.05448v4.pdf",
    "authors": [
      "Mengwei Xu",
      "Jiawei Liu",
      "Yuanqiang Liu",
      "Felix Xiaozhu Lin",
      "Yunxin Liu",
      "Xuanzhe Liu"
    ]
  },
  {
    "title": "Geometrization of deep networks for the interpretability of deep\n  learning systems",
    "text": "Geometrization of deep networks for the interpretability of deep\n  learning systems. How to understand deep learning systems remains an open problem. In this\npaper we propose that the answer may lie in the geometrization of deep\nnetworks. Geometrization is a bridge to connect physics, geometry, deep network\nand quantum computation and this may result in a new scheme to reveal the rule\nof the physical world. By comparing the geometry of image matching and deep\nnetworks, we show that geometrization of deep networks can be used to\nunderstand existing deep learning systems and it may also help to solve the\ninterpretability problem of deep learning systems.",
    "pdf_link": "http://arxiv.org/pdf/1901.02354v2.pdf",
    "authors": [
      "Xiao Dong",
      "Ling Zhou"
    ]
  },
  {
    "title": "Why & When Deep Learning Works: Looking Inside Deep Learnings",
    "text": "Why & When Deep Learning Works: Looking Inside Deep Learnings. The Intel Collaborative Research Institute for Computational Intelligence\n(ICRI-CI) has been heavily supporting Machine Learning and Deep Learning\nresearch from its foundation in 2012. We have asked six leading ICRI-CI Deep\nLearning researchers to address the challenge of \"Why & When Deep Learning\nworks\", with the goal of looking inside Deep Learning, providing insights on\nhow deep networks function, and uncovering key observations on their\nexpressiveness, limitations, and potential. The output of this challenge\nresulted in five papers that address different facets of deep learning. These\ndifferent facets include a high-level understating of why and when deep\nnetworks work (and do not work), the impact of geometry on the expressiveness\nof deep networks, and making deep networks interpretable.",
    "pdf_link": "http://arxiv.org/pdf/1705.03921v1.pdf",
    "authors": [
      "Ronny Ronen"
    ]
  },
  {
    "title": "Learning Task-aware Robust Deep Learning Systems",
    "text": "Learning Task-aware Robust Deep Learning Systems. Many works demonstrate that deep learning system is vulnerable to adversarial\nattack. A deep learning system consists of two parts: the deep learning task\nand the deep model. Nowadays, most existing works investigate the impact of the\ndeep model on robustness of deep learning systems, ignoring the impact of the\nlearning task. In this paper, we adopt the binary and interval label encoding\nstrategy to redefine the classification task and design corresponding loss to\nimprove robustness of the deep learning system. Our method can be viewed as\nimproving the robustness of deep learning systems from both the learning task\nand deep model. Experimental results demonstrate that our learning task-aware\nmethod is much more robust than traditional classification while retaining the\naccuracy.",
    "pdf_link": "http://arxiv.org/pdf/2010.05125v2.pdf",
    "authors": [
      "Keji Han",
      "Yun Li",
      "Xianzhong Long",
      "Yao Ge"
    ]
  },
  {
    "title": "Deep Learning in Software Engineering",
    "text": "Deep Learning in Software Engineering. Recent years, deep learning is increasingly prevalent in the field of\nSoftware Engineering (SE). However, many open issues still remain to be\ninvestigated. How do researchers integrate deep learning into SE problems?\nWhich SE phases are facilitated by deep learning? Do practitioners benefit from\ndeep learning? The answers help practitioners and researchers develop practical\ndeep learning models for SE tasks. To answer these questions, we conduct a\nbibliography analysis on 98 research papers in SE that use deep learning\ntechniques. We find that 41 SE tasks in all SE phases have been facilitated by\ndeep learning integrated solutions. In which, 84.7% papers only use standard\ndeep learning models and their variants to solve SE problems. The\npracticability becomes a concern in utilizing deep learning techniques. How to\nimprove the effectiveness, efficiency, understandability, and testability of\ndeep learning based solutions may attract more SE researchers in the future.",
    "pdf_link": "http://arxiv.org/pdf/1805.04825v1.pdf",
    "authors": [
      "Xiaochen Li",
      "He Jiang",
      "Zhilei Ren",
      "Ge Li",
      "Jingxuan Zhang"
    ]
  },
  {
    "title": "Moving Deep Learning into Web Browser: How Far Can We Go?",
    "text": "Moving Deep Learning into Web Browser: How Far Can We Go?. Recently, several JavaScript-based deep learning frameworks have emerged,\nmaking it possible to perform deep learning tasks directly in browsers.\nHowever, little is known on what and how well we can do with these frameworks\nfor deep learning in browsers. To bridge the knowledge gap, in this paper, we\nconduct the first empirical study of deep learning in browsers. We survey 7\nmost popular JavaScript-based deep learning frameworks, investigating to what\nextent deep learning tasks have been supported in browsers so far. Then we\nmeasure the performance of different frameworks when running different deep\nlearning tasks. Finally, we dig out the performance gap between deep learning\nin browsers and on native platforms by comparing the performance of\nTensorFlow.js and TensorFlow in Python. Our findings could help application\ndevelopers, deep-learning framework vendors and browser vendors to improve the\nefficiency of deep learning in browsers.",
    "pdf_link": "http://arxiv.org/pdf/1901.09388v2.pdf",
    "authors": [
      "Yun Ma",
      "Dongwei Xiang",
      "Shuyu Zheng",
      "Deyu Tian",
      "Xuanzhe Liu"
    ]
  },
  {
    "title": "Greedy Deep Dictionary Learning",
    "text": "Greedy Deep Dictionary Learning. In this work we propose a new deep learning tool called deep dictionary\nlearning. Multi-level dictionaries are learnt in a greedy fashion, one layer at\na time. This requires solving a simple (shallow) dictionary learning problem,\nthe solution to this is well known. We apply the proposed technique on some\nbenchmark deep learning datasets. We compare our results with other deep\nlearning tools like stacked autoencoder and deep belief network; and state of\nthe art supervised dictionary learning tools like discriminative KSVD and label\nconsistent KSVD. Our method yields better results than all.",
    "pdf_link": "http://arxiv.org/pdf/1602.00203v1.pdf",
    "authors": [
      "Snigdha Tariyal",
      "Angshul Majumdar",
      "Richa Singh",
      "Mayank Vatsa"
    ]
  },
  {
    "title": "Quantum Neural Networks: Concepts, Applications, and Challenges",
    "text": "Quantum Neural Networks: Concepts, Applications, and Challenges. Quantum deep learning is a research field for the use of quantum computing\ntechniques for training deep neural networks. The research topics and\ndirections of deep learning and quantum computing have been separated for long\ntime, however by discovering that quantum circuits can act like artificial\nneural networks, quantum deep learning research is widely adopted. This paper\nexplains the backgrounds and basic principles of quantum deep learning and also\nintroduces major achievements. After that, this paper discusses the challenges\nof quantum deep learning research in multiple perspectives. Lastly, this paper\npresents various future research directions and application fields of quantum\ndeep learning.",
    "pdf_link": "http://arxiv.org/pdf/2108.01468v1.pdf",
    "authors": [
      "Yunseok Kwak",
      "Won Joon Yun",
      "Soyi Jung",
      "Joongheon Kim"
    ]
  },
  {
    "title": "NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders\n  of Deep Giants",
    "text": "NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders\n  of Deep Giants. Tiny deep learning has attracted increasing attention driven by the\nsubstantial demand for deploying deep learning on numerous intelligent\nInternet-of-Things devices. However, it is still challenging to unleash tiny\ndeep learning's full potential on both large-scale datasets and downstream\ntasks due to the under-fitting issues caused by the limited model capacity of\ntiny neural networks (TNNs). To this end, we propose a framework called\nNetBooster to empower tiny deep learning by augmenting the architectures of\nTNNs via an expansion-then-contraction strategy. Extensive experiments show\nthat NetBooster consistently outperforms state-of-the-art tiny deep learning\nsolutions.",
    "pdf_link": "http://arxiv.org/pdf/2306.13586v1.pdf",
    "authors": [
      "Zhongzhi Yu",
      "Yonggan Fu",
      "Jiayi Yuan",
      "Haoran You",
      "Yingyan Lin"
    ]
  },
  {
    "title": "Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey",
    "text": "Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey. Deep reinforcement learning augments the reinforcement learning framework and\nutilizes the powerful representation of deep neural networks. Recent works have\ndemonstrated the remarkable successes of deep reinforcement learning in various\ndomains including finance, medicine, healthcare, video games, robotics, and\ncomputer vision. In this work, we provide a detailed review of recent and\nstate-of-the-art research advances of deep reinforcement learning in computer\nvision. We start with comprehending the theories of deep learning,\nreinforcement learning, and deep reinforcement learning. We then propose a\ncategorization of deep reinforcement learning methodologies and discuss their\nadvantages and limitations. In particular, we divide deep reinforcement\nlearning into seven main categories according to their applications in computer\nvision, i.e. (i)landmark localization (ii) object detection; (iii) object\ntracking; (iv) registration on both 2D image and 3D image volumetric data (v)\nimage segmentation; (vi) videos analysis; and (vii) other applications. Each of\nthese categories is further analyzed with reinforcement learning techniques,\nnetwork design, and performance. Moreover, we provide a comprehensive analysis\nof the existing publicly available datasets and examine source code\navailability. Finally, we present some open issues and discuss future research\ndirections on deep reinforcement learning in computer vision",
    "pdf_link": "http://arxiv.org/pdf/2108.11510v1.pdf",
    "authors": [
      "Ngan Le",
      "Vidhiwar Singh Rathour",
      "Kashu Yamazaki",
      "Khoa Luu",
      "Marios Savvides"
    ]
  },
  {
    "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep\n  Probabilistic Models",
    "text": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep\n  Probabilistic Models. Probabilistic deep learning is deep learning that accounts for uncertainty,\nboth model uncertainty and data uncertainty. It is based on the use of\nprobabilistic models and deep neural networks. We distinguish two approaches to\nprobabilistic deep learning: probabilistic neural networks and deep\nprobabilistic models. The former employs deep neural networks that utilize\nprobabilistic layers which can represent and process uncertainty; the latter\nuses probabilistic models that incorporate deep neural network components which\ncapture complex non-linear stochastic relationships between the random\nvariables. We discuss some major examples of each approach including Bayesian\nneural networks and mixture density networks (for probabilistic neural\nnetworks), and variational autoencoders, deep Gaussian processes and deep mixed\neffects models (for deep probabilistic models). TensorFlow Probability is a\nlibrary for probabilistic modeling and inference which can be used for both\napproaches of probabilistic deep learning. We include its code examples for\nillustration.",
    "pdf_link": "http://arxiv.org/pdf/2106.00120v3.pdf",
    "authors": [
      "Daniel T. Chang"
    ]
  },
  {
    "title": "Towards energy-efficient Deep Learning: An overview of energy-efficient\n  approaches along the Deep Learning Lifecycle",
    "text": "Towards energy-efficient Deep Learning: An overview of energy-efficient\n  approaches along the Deep Learning Lifecycle. Deep Learning has enabled many advances in machine learning applications in\nthe last few years. However, since current Deep Learning algorithms require\nmuch energy for computations, there are growing concerns about the associated\nenvironmental costs. Energy-efficient Deep Learning has received much attention\nfrom researchers and has already made much progress in the last couple of\nyears. This paper aims to gather information about these advances from the\nliterature and show how and at which points along the lifecycle of Deep\nLearning (IT-Infrastructure, Data, Modeling, Training, Deployment, Evaluation)\nit is possible to reduce energy consumption.",
    "pdf_link": "http://arxiv.org/pdf/2303.01980v1.pdf",
    "authors": [
      "Vanessa Mehlin",
      "Sigurd Schacht",
      "Carsten Lanquillon"
    ]
  },
  {
    "title": "A Unified Framework of Deep Neural Networks by Capsules",
    "text": "A Unified Framework of Deep Neural Networks by Capsules. With the growth of deep learning, how to describe deep neural networks\nunifiedly is becoming an important issue. We first formalize neural networks\nmathematically with their directed graph representations, and prove a\ngeneration theorem about the induced networks of connected directed acyclic\ngraphs. Then, we set up a unified framework for deep learning with capsule\nnetworks. This capsule framework could simplify the description of existing\ndeep neural networks, and provide a theoretical basis of graphic designing and\nprogramming techniques for deep learning models, thus would be of great\nsignificance to the advancement of deep learning.",
    "pdf_link": "http://arxiv.org/pdf/1805.03551v2.pdf",
    "authors": [
      "Yujian Li",
      "Chuanhui Shan"
    ]
  },
  {
    "title": "Integrating Learning and Reasoning with Deep Logic Models",
    "text": "Integrating Learning and Reasoning with Deep Logic Models. Deep learning is very effective at jointly learning feature representations\nand classification models, especially when dealing with high dimensional input\npatterns. Probabilistic logic reasoning, on the other hand, is capable to take\nconsistent and robust decisions in complex environments. The integration of\ndeep learning and logic reasoning is still an open-research problem and it is\nconsidered to be the key for the development of real intelligent agents. This\npaper presents Deep Logic Models, which are deep graphical models integrating\ndeep learning and logic reasoning both for learning and inference. Deep Logic\nModels create an end-to-end differentiable architecture, where deep learners\nare embedded into a network implementing a continuous relaxation of the logic\nknowledge. The learning process allows to jointly learn the weights of the deep\nlearners and the meta-parameters controlling the high-level reasoning. The\nexperimental results show that the proposed methodology overtakes the\nlimitations of the other approaches that have been proposed to bridge deep\nlearning and reasoning.",
    "pdf_link": "http://arxiv.org/pdf/1901.04195v1.pdf",
    "authors": [
      "Giuseppe Marra",
      "Francesco Giannini",
      "Michelangelo Diligenti",
      "Marco Gori"
    ]
  },
  {
    "title": "Deep Learning in the Field of Biometric Template Protection: An Overview",
    "text": "Deep Learning in the Field of Biometric Template Protection: An Overview. Today, deep learning represents the most popular and successful form of\nmachine learning. Deep learning has revolutionised the field of pattern\nrecognition, including biometric recognition. Biometric systems utilising deep\nlearning have been shown to achieve auspicious recognition accuracy, surpassing\nhuman performance. Apart from said breakthrough advances in terms of biometric\nperformance, the use of deep learning was reported to impact different\ncovariates of biometrics such as algorithmic fairness, vulnerability to\nattacks, or template protection. Technologies of biometric template protection\nare designed to enable a secure and privacy-preserving deployment of\nbiometrics. In the recent past, deep learning techniques have been frequently\napplied in biometric template protection systems for various purposes. This\nwork provides an overview of how advances in deep learning take influence on\nthe field of biometric template protection. The interrelation between improved\nbiometric performance rates and security in biometric template protection is\nelaborated. Further, the use of deep learning for obtaining feature\nrepresentations that are suitable for biometric template protection is\ndiscussed. Novel methods that apply deep learning to achieve various goals of\nbiometric template protection are surveyed along with deep learning-based\nattacks.",
    "pdf_link": "http://arxiv.org/pdf/2303.02715v1.pdf",
    "authors": [
      "Christian Rathgeb",
      "Jascha Kolberg",
      "Andreas Uhl",
      "Christoph Busch"
    ]
  },
  {
    "title": "A Survey Analyzing Generalization in Deep Reinforcement Learning",
    "text": "A Survey Analyzing Generalization in Deep Reinforcement Learning. Reinforcement learning research obtained significant success and attention\nwith the utilization of deep neural networks to solve problems in high\ndimensional state or action spaces. While deep reinforcement learning policies\nare currently being deployed in many different fields from medical applications\nto large language models, there are still ongoing questions the field is trying\nto answer on the generalization capabilities of deep reinforcement learning\npolicies. In this paper, we will formalize and analyze generalization in deep\nreinforcement learning. We will explain the fundamental reasons why deep\nreinforcement learning policies encounter overfitting problems that limit their\ngeneralization capabilities. Furthermore, we will categorize and explain the\nmanifold solution approaches to increase generalization, and overcome\noverfitting in deep reinforcement learning policies. From exploration to\nadversarial analysis and from regularization to robustness our paper provides\nan analysis on a wide range of subfields within deep reinforcement learning\nwith a broad scope and in-depth view. We believe our study can provide a\ncompact guideline for the current advancements in deep reinforcement learning,\nand help to construct robust deep neural policies with higher generalization\nskills.",
    "pdf_link": "http://arxiv.org/pdf/2401.02349v2.pdf",
    "authors": [
      "Ezgi Korkmaz"
    ]
  },
  {
    "title": "Transferability in Deep Learning: A Survey",
    "text": "Transferability in Deep Learning: A Survey. The success of deep learning algorithms generally depends on large-scale\ndata, while humans appear to have inherent ability of knowledge transfer, by\nrecognizing and applying relevant knowledge from previous learning experiences\nwhen encountering and solving unseen tasks. Such an ability to acquire and\nreuse knowledge is known as transferability in deep learning. It has formed the\nlong-term quest towards making deep learning as data-efficient as human\nlearning, and has been motivating fruitful design of more powerful deep\nlearning algorithms. We present this survey to connect different isolated areas\nin deep learning with their relation to transferability, and to provide a\nunified and complete view to investigating transferability through the whole\nlifecycle of deep learning. The survey elaborates the fundamental goals and\nchallenges in parallel with the core principles and methods, covering recent\ncornerstones in deep architectures, pre-training, task adaptation and domain\nadaptation. This highlights unanswered questions on the appropriate objectives\nfor learning transferable knowledge and for adapting the knowledge to new tasks\nand domains, avoiding catastrophic forgetting and negative transfer. Finally,\nwe implement a benchmark and an open-source library, enabling a fair evaluation\nof deep learning methods in terms of transferability.",
    "pdf_link": "http://arxiv.org/pdf/2201.05867v1.pdf",
    "authors": [
      "Junguang Jiang",
      "Yang Shu",
      "Jianmin Wang",
      "Mingsheng Long"
    ]
  },
  {
    "title": "What Really is Deep Learning Doing?",
    "text": "What Really is Deep Learning Doing?. Deep learning has achieved a great success in many areas, from computer\nvision to natural language processing, to game playing, and much more. Yet,\nwhat deep learning is really doing is still an open question. There are a lot\nof works in this direction. For example, [5] tried to explain deep learning by\ngroup renormalization, and [6] tried to explain deep learning from the view of\nfunctional approximation. In order to address this very crucial question, here\nwe see deep learning from perspective of mechanical learning and learning\nmachine (see [1], [2]). From this particular angle, we can see deep learning\nmuch better and answer with confidence: What deep learning is really doing? why\nit works well, how it works, and how much data is necessary for learning. We\nalso will discuss advantages and disadvantages of deep learning at the end of\nthis work.",
    "pdf_link": "http://arxiv.org/pdf/1711.03577v1.pdf",
    "authors": [
      "Chuyu Xiong"
    ]
  },
  {
    "title": "Feature versus Raw Sequence: Deep Learning Comparative Study on\n  Predicting Pre-miRNA",
    "text": "Feature versus Raw Sequence: Deep Learning Comparative Study on\n  Predicting Pre-miRNA. Should we input known genome sequence features or input sequence itself in\ndeep learning framework? As deep learning more popular in various applications,\nresearchers often come to question whether to generate features or use raw\nsequences for deep learning. To answer this question, we study the prediction\naccuracy of precursor miRNA prediction of feature-based deep belief network and\nsequence-based convolution neural network. Tested on a variant of six-layer\nconvolution neural net and three-layer deep belief network, we find the raw\nsequence input based convolution neural network model performs similar or\nslightly better than feature based deep belief networks with best accuracy\nvalues of 0.995 and 0.990, respectively. Both the models outperform existing\nbenchmarks models. The results shows us that if provided large enough data,\nwell devised raw sequence based deep learning models can replace feature based\ndeep learning models. However, construction of well behaved deep learning model\ncan be very challenging. In cased features can be easily extracted,\nfeature-based deep learning models may be a better alternative.",
    "pdf_link": "http://arxiv.org/pdf/1710.06798v1.pdf",
    "authors": [
      "Jaya Thomas",
      "Sonia Thomas",
      "Lee Sael"
    ]
  },
  {
    "title": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player\n  Multi-Agent Learning Toolbox",
    "text": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player\n  Multi-Agent Learning Toolbox. With the breakthrough of AlphaGo, deep reinforcement learning becomes a\nrecognized technique for solving sequential decision-making problems. Despite\nits reputation, data inefficiency caused by its trial and error learning\nmechanism makes deep reinforcement learning hard to be practical in a wide\nrange of areas. Plenty of methods have been developed for sample efficient deep\nreinforcement learning, such as environment modeling, experience transfer, and\ndistributed modifications, amongst which, distributed deep reinforcement\nlearning has shown its potential in various applications, such as\nhuman-computer gaming, and intelligent transportation. In this paper, we\nconclude the state of this exciting field, by comparing the classical\ndistributed deep reinforcement learning methods, and studying important\ncomponents to achieve efficient distributed learning, covering single player\nsingle agent distributed deep reinforcement learning to the most complex\nmultiple players multiple agents distributed deep reinforcement learning.\nFurthermore, we review recently released toolboxes that help to realize\ndistributed deep reinforcement learning without many modifications of their\nnon-distributed versions. By analyzing their strengths and weaknesses, a\nmulti-player multi-agent distributed deep reinforcement learning toolbox is\ndeveloped and released, which is further validated on Wargame, a complex\nenvironment, showing usability of the proposed toolbox for multiple players and\nmultiple agents distributed deep reinforcement learning under complex games.\nFinally, we try to point out challenges and future trends, hoping this brief\nreview can provide a guide or a spark for researchers who are interested in\ndistributed deep reinforcement learning.",
    "pdf_link": "http://arxiv.org/pdf/2212.00253v1.pdf",
    "authors": [
      "Qiyue Yin",
      "Tongtong Yu",
      "Shengqi Shen",
      "Jun Yang",
      "Meijing Zhao",
      "Kaiqi Huang",
      "Bin Liang",
      "Liang Wang"
    ]
  },
  {
    "title": "Are Efficient Deep Representations Learnable?",
    "text": "Are Efficient Deep Representations Learnable?. Many theories of deep learning have shown that a deep network can require\ndramatically fewer resources to represent a given function compared to a\nshallow network. But a question remains: can these efficient representations be\nlearned using current deep learning techniques? In this work, we test whether\nstandard deep learning methods can in fact find the efficient representations\nposited by several theories of deep representation. Specifically, we train deep\nneural networks to learn two simple functions with known efficient solutions:\nthe parity function and the fast Fourier transform. We find that using\ngradient-based optimization, a deep network does not learn the parity function,\nunless initialized very close to a hand-coded exact solution. We also find that\na deep linear neural network does not learn the fast Fourier transform, even in\nthe best-case scenario of infinite training data, unless the weights are\ninitialized very close to the exact hand-coded solution. Our results suggest\nthat not every element of the class of compositional functions can be learned\nefficiently by a deep network, and further restrictions are necessary to\nunderstand what functions are both efficiently representable and learnable.",
    "pdf_link": "http://arxiv.org/pdf/1807.06399v1.pdf",
    "authors": [
      "Maxwell Nye",
      "Andrew Saxe"
    ]
  },
  {
    "title": "Deep Learning: A Critical Appraisal",
    "text": "Deep Learning: A Critical Appraisal. Although deep learning has historical roots going back decades, neither the\nterm \"deep learning\" nor the approach was popular just over five years ago,\nwhen the field was reignited by papers such as Krizhevsky, Sutskever and\nHinton's now classic (2012) deep network model of Imagenet. What has the field\ndiscovered in the five subsequent years? Against a background of considerable\nprogress in areas such as speech recognition, image recognition, and game\nplaying, and considerable enthusiasm in the popular press, I present ten\nconcerns for deep learning, and suggest that deep learning must be supplemented\nby other techniques if we are to reach artificial general intelligence.",
    "pdf_link": "http://arxiv.org/pdf/1801.00631v1.pdf",
    "authors": [
      "Gary Marcus"
    ]
  },
  {
    "title": "Deep Learning for Sentiment Analysis : A Survey",
    "text": "Deep Learning for Sentiment Analysis : A Survey. Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.",
    "pdf_link": "http://arxiv.org/pdf/1801.07883v2.pdf",
    "authors": [
      "Lei Zhang",
      "Shuai Wang",
      "Bing Liu"
    ]
  },
  {
    "title": "Deep Learning for Visual Navigation of Underwater Robots",
    "text": "Deep Learning for Visual Navigation of Underwater Robots. This paper aims to briefly survey deep learning methods for visual navigation\nof underwater robotics. The scope of this paper includes the visual perception\nof underwater robotics with deep learning methods, the available visual\nunderwater datasets, imitation learning, and reinforcement learning methods for\nnavigation. Additionally, relevant works will be categorized under the\nimitation learning or deep learning paradigm for underwater robots for clarity\nof the training methodologies in the current landscape. Literature that uses\ndeep learning algorithms to process non-visual data for underwater navigation\nwill not be considered, except as contrasting examples.",
    "pdf_link": "http://arxiv.org/pdf/2310.19495v1.pdf",
    "authors": [
      "M. Sunbeam"
    ]
  },
  {
    "title": "When deep learning meets security",
    "text": "When deep learning meets security. Deep learning is an emerging research field that has proven its effectiveness\ntowards deploying more efficient intelligent systems. Security, on the other\nhand, is one of the most essential issues in modern communication systems.\nRecently many papers have shown that using deep learning models can achieve\npromising results when applied to the security domain. In this work, we provide\nan overview for the recent studies that apply deep learning techniques to the\nfield of security.",
    "pdf_link": "http://arxiv.org/pdf/1807.04739v1.pdf",
    "authors": [
      "Majd Latah"
    ]
  },
  {
    "title": "Deep Causal Learning for Robotic Intelligence",
    "text": "Deep Causal Learning for Robotic Intelligence. This invited review discusses causal learning in the context of robotic\nintelligence. The paper introduced the psychological findings on causal\nlearning in human cognition, then it introduced the traditional statistical\nsolutions on causal discovery and causal inference. The paper reviewed recent\ndeep causal learning algorithms with a focus on their architectures and the\nbenefits of using deep nets and discussed the gap between deep causal learning\nand the needs of robotic intelligence.",
    "pdf_link": "http://arxiv.org/pdf/2212.12597v1.pdf",
    "authors": [
      "Yangming Li"
    ]
  },
  {
    "title": "Deep learning in radiology: an overview of the concepts and a survey of\n  the state of the art",
    "text": "Deep learning in radiology: an overview of the concepts and a survey of\n  the state of the art. Deep learning is a branch of artificial intelligence where networks of simple\ninterconnected units are used to extract patterns from data in order to solve\ncomplex problems. Deep learning algorithms have shown groundbreaking\nperformance in a variety of sophisticated tasks, especially those related to\nimages. They have often matched or exceeded human performance. Since the\nmedical field of radiology mostly relies on extracting useful information from\nimages, it is a very natural application area for deep learning, and research\nin this area has rapidly grown in recent years. In this article, we review the\nclinical reality of radiology and discuss the opportunities for application of\ndeep learning algorithms. We also introduce basic concepts of deep learning\nincluding convolutional neural networks. Then, we present a survey of the\nresearch in deep learning applied to radiology. We organize the studies by the\ntypes of specific tasks that they attempt to solve and review the broad range\nof utilized deep learning algorithms. Finally, we briefly discuss opportunities\nand challenges for incorporating deep learning in the radiology practice of the\nfuture.",
    "pdf_link": "http://arxiv.org/pdf/1802.08717v1.pdf",
    "authors": [
      "Maciej A. Mazurowski",
      "Mateusz Buda",
      "Ashirbani Saha",
      "Mustafa R. Bashir"
    ]
  },
  {
    "title": "A Selective Overview of Deep Learning",
    "text": "A Selective Overview of Deep Learning. Deep learning has arguably achieved tremendous success in recent years. In\nsimple words, deep learning uses the composition of many nonlinear functions to\nmodel the complex dependency between input features and labels. While neural\nnetworks have a long history, recent advances have greatly improved their\nperformance in computer vision, natural language processing, etc. From the\nstatistical and scientific perspective, it is natural to ask: What is deep\nlearning? What are the new characteristics of deep learning, compared with\nclassical methods? What are the theoretical foundations of deep learning? To\nanswer these questions, we introduce common neural network models (e.g.,\nconvolutional neural nets, recurrent neural nets, generative adversarial nets)\nand training techniques (e.g., stochastic gradient descent, dropout, batch\nnormalization) from a statistical point of view. Along the way, we highlight\nnew characteristics of deep learning (including depth and over-parametrization)\nand explain their practical and theoretical benefits. We also sample recent\nresults on theories of deep learning, many of which are only suggestive. While\na complete understanding of deep learning remains elusive, we hope that our\nperspectives and discussions serve as a stimulus for new statistical research.",
    "pdf_link": "http://arxiv.org/pdf/1904.05526v2.pdf",
    "authors": [
      "Jianqing Fan",
      "Cong Ma",
      "Yiqiao Zhong"
    ]
  },
  {
    "title": "A Survey on Deep Learning Methods for Robot Vision",
    "text": "A Survey on Deep Learning Methods for Robot Vision. Deep learning has allowed a paradigm shift in pattern recognition, from using\nhand-crafted features together with statistical classifiers to using\ngeneral-purpose learning procedures for learning data-driven representations,\nfeatures, and classifiers together. The application of this new paradigm has\nbeen particularly successful in computer vision, in which the development of\ndeep learning methods for vision applications has become a hot research topic.\nGiven that deep learning has already attracted the attention of the robot\nvision community, the main purpose of this survey is to address the use of deep\nlearning in robot vision. To achieve this, a comprehensive overview of deep\nlearning and its usage in computer vision is given, that includes a description\nof the most frequently used neural models and their main application areas.\nThen, the standard methodology and tools used for designing deep-learning based\nvision systems are presented. Afterwards, a review of the principal work using\ndeep learning in robot vision is presented, as well as current and future\ntrends related to the use of deep learning in robotics. This survey is intended\nto be a guide for the developers of robot vision systems.",
    "pdf_link": "http://arxiv.org/pdf/1803.10862v1.pdf",
    "authors": [
      "Javier Ruiz-del-Solar",
      "Patricio Loncomilla",
      "Naiomi Soto"
    ]
  },
  {
    "title": "Interpretations of Deep Learning by Forests and Haar Wavelets",
    "text": "Interpretations of Deep Learning by Forests and Haar Wavelets. This paper presents a basic property of region dividing of ReLU (rectified\nlinear unit) deep learning when new layers are successively added, by which two\nnew perspectives of interpreting deep learning are given. The first is related\nto decision trees and forests; we construct a deep learning structure\nequivalent to a forest in classification abilities, which means that certain\nkinds of ReLU deep learning can be considered as forests. The second\nperspective is that Haar wavelet represented functions can be approximated by\nReLU deep learning with arbitrary precision; and then a general conclusion of\nfunction approximation abilities of ReLU deep learning is given. Finally,\ngeneralize some of the conclusions of ReLU deep learning to the case of\nsigmoid-unit deep learning.",
    "pdf_link": "http://arxiv.org/pdf/1906.06706v7.pdf",
    "authors": [
      "Changcun Huang"
    ]
  },
  {
    "title": "A Brief Survey of Deep Reinforcement Learning",
    "text": "A Brief Survey of Deep Reinforcement Learning. Deep reinforcement learning is poised to revolutionise the field of AI and\nrepresents a step towards building autonomous systems with a higher level\nunderstanding of the visual world. Currently, deep learning is enabling\nreinforcement learning to scale to problems that were previously intractable,\nsuch as learning to play video games directly from pixels. Deep reinforcement\nlearning algorithms are also applied to robotics, allowing control policies for\nrobots to be learned directly from camera inputs in the real world. In this\nsurvey, we begin with an introduction to the general field of reinforcement\nlearning, then progress to the main streams of value-based and policy-based\nmethods. Our survey will cover central algorithms in deep reinforcement\nlearning, including the deep $Q$-network, trust region policy optimisation, and\nasynchronous advantage actor-critic. In parallel, we highlight the unique\nadvantages of deep neural networks, focusing on visual understanding via\nreinforcement learning. To conclude, we describe several current areas of\nresearch within the field.",
    "pdf_link": "http://arxiv.org/pdf/1708.05866v2.pdf",
    "authors": [
      "Kai Arulkumaran",
      "Marc Peter Deisenroth",
      "Miles Brundage",
      "Anil Anthony Bharath"
    ]
  },
  {
    "title": "Topological Deep Learning: A Review of an Emerging Paradigm",
    "text": "Topological Deep Learning: A Review of an Emerging Paradigm. Topological data analysis (TDA) provides insight into data shape. The\nsummaries obtained by these methods are principled global descriptions of\nmulti-dimensional data whilst exhibiting stable properties such as robustness\nto deformation and noise. Such properties are desirable in deep learning\npipelines but they are typically obtained using non-TDA strategies. This is\npartly caused by the difficulty of combining TDA constructs (e.g. barcode and\npersistence diagrams) with current deep learning algorithms. Fortunately, we\nare now witnessing a growth of deep learning applications embracing\ntopologically-guided components. In this survey, we review the nascent field of\ntopological deep learning by first revisiting the core concepts of TDA. We then\nexplore how the use of TDA techniques has evolved over time to support deep\nlearning frameworks, and how they can be integrated into different aspects of\ndeep learning. Furthermore, we touch on TDA usage for analyzing existing deep\nmodels; deep topological analytics. Finally, we discuss the challenges and\nfuture prospects of topological deep learning.",
    "pdf_link": "http://arxiv.org/pdf/2302.03836v1.pdf",
    "authors": [
      "Ali Zia",
      "Abdelwahed Khamis",
      "James Nichols",
      "Zeeshan Hayder",
      "Vivien Rolland",
      "Lars Petersson"
    ]
  },
  {
    "title": "Generalization and Expressivity for Deep Nets",
    "text": "Generalization and Expressivity for Deep Nets. Along with the rapid development of deep learning in practice, the\ntheoretical explanations for its success become urgent. Generalization and\nexpressivity are two widely used measurements to quantify theoretical behaviors\nof deep learning. The expressivity focuses on finding functions expressible by\ndeep nets but cannot be approximated by shallow nets with the similar number of\nneurons. It usually implies the large capacity. The generalization aims at\nderiving fast learning rate for deep nets. It usually requires small capacity\nto reduce the variance. Different from previous studies on deep learning,\npursuing either expressivity or generalization, we take both factors into\naccount to explore the theoretical advantages of deep nets. For this purpose,\nwe construct a deep net with two hidden layers possessing excellent\nexpressivity in terms of localized and sparse approximation. Then, utilizing\nthe well known covering number to measure the capacity, we find that deep nets\npossess excellent expressive power (measured by localized and sparse\napproximation) without enlarging the capacity of shallow nets. As a\nconsequence, we derive near optimal learning rates for implementing empirical\nrisk minimization (ERM) on the constructed deep nets. These results\ntheoretically exhibit the advantage of deep nets from learning theory\nviewpoints.",
    "pdf_link": "http://arxiv.org/pdf/1803.03772v2.pdf",
    "authors": [
      "Shao-Bo Lin"
    ]
  },
  {
    "title": "Deep Incremental Boosting",
    "text": "Deep Incremental Boosting. This paper introduces Deep Incremental Boosting, a new technique derived from\nAdaBoost, specifically adapted to work with Deep Learning methods, that reduces\nthe required training time and improves generalisation. We draw inspiration\nfrom Transfer of Learning approaches to reduce the start-up time to training\neach incremental Ensemble member. We show a set of experiments that outlines\nsome preliminary results on some common Deep Learning datasets and discuss the\npotential improvements Deep Incremental Boosting brings to traditional Ensemble\nmethods in Deep Learning.",
    "pdf_link": "http://arxiv.org/pdf/1708.03704v1.pdf",
    "authors": [
      "Alan Mosca",
      "George D Magoulas"
    ]
  },
  {
    "title": "Combining Deep Learning with Good Old-Fashioned Machine Learning",
    "text": "Combining Deep Learning with Good Old-Fashioned Machine Learning. We present a comprehensive, stacking-based framework for combining deep\nlearning with good old-fashioned machine learning, called Deep GOld. Our\nframework involves ensemble selection from 51 retrained pretrained deep\nnetworks as first-level models, and 10 machine-learning algorithms as\nsecond-level models. Enabled by today's state-of-the-art software tools and\nhardware platforms, Deep GOld delivers consistent improvement when tested on\nfour image-classification datasets: Fashion MNIST, CIFAR10, CIFAR100, and Tiny\nImageNet. Of 120 experiments, in all but 10 Deep GOld improved the original\nnetworks' performance.",
    "pdf_link": "http://arxiv.org/pdf/2207.03757v2.pdf",
    "authors": [
      "Moshe Sipper"
    ]
  },
  {
    "title": "Deep frequency principle towards understanding why deeper learning is\n  faster",
    "text": "Deep frequency principle towards understanding why deeper learning is\n  faster. Understanding the effect of depth in deep learning is a critical problem. In\nthis work, we utilize the Fourier analysis to empirically provide a promising\nmechanism to understand why feedforward deeper learning is faster. To this end,\nwe separate a deep neural network, trained by normal stochastic gradient\ndescent, into two parts during analysis, i.e., a pre-condition component and a\nlearning component, in which the output of the pre-condition one is the input\nof the learning one. We use a filtering method to characterize the frequency\ndistribution of a high-dimensional function. Based on experiments of deep\nnetworks and real dataset, we propose a deep frequency principle, that is, the\neffective target function for a deeper hidden layer biases towards lower\nfrequency during the training. Therefore, the learning component effectively\nlearns a lower frequency function if the pre-condition component has more\nlayers. Due to the well-studied frequency principle, i.e., deep neural networks\nlearn lower frequency functions faster, the deep frequency principle provides a\nreasonable explanation to why deeper learning is faster. We believe these\nempirical studies would be valuable for future theoretical studies of the\neffect of depth in deep learning.",
    "pdf_link": "http://arxiv.org/pdf/2007.14313v2.pdf",
    "authors": [
      "Zhi-Qin John Xu",
      "Hanxu Zhou"
    ]
  },
  {
    "title": "Deep Bayesian Active Learning with Image Data",
    "text": "Deep Bayesian Active Learning with Image Data. Even though active learning forms an important pillar of machine learning,\ndeep learning tools are not prevalent within it. Deep learning poses several\ndifficulties when used in an active learning setting. First, active learning\n(AL) methods generally rely on being able to learn and update models from small\namounts of data. Recent advances in deep learning, on the other hand, are\nnotorious for their dependence on large amounts of data. Second, many AL\nacquisition functions rely on model uncertainty, yet deep learning methods\nrarely represent such model uncertainty. In this paper we combine recent\nadvances in Bayesian deep learning into the active learning framework in a\npractical way. We develop an active learning framework for high dimensional\ndata, a task which has been extremely challenging so far, with very sparse\nexisting literature. Taking advantage of specialised models such as Bayesian\nconvolutional neural networks, we demonstrate our active learning techniques\nwith image data, obtaining a significant improvement on existing active\nlearning approaches. We demonstrate this on both the MNIST dataset, as well as\nfor skin cancer diagnosis from lesion images (ISIC2016 task).",
    "pdf_link": "http://arxiv.org/pdf/1703.02910v1.pdf",
    "authors": [
      "Yarin Gal",
      "Riashat Islam",
      "Zoubin Ghahramani"
    ]
  },
  {
    "title": "Deep Learning for Genomics: A Concise Overview",
    "text": "Deep Learning for Genomics: A Concise Overview. Advancements in genomic research such as high-throughput sequencing\ntechniques have driven modern genomic studies into \"big data\" disciplines. This\ndata explosion is constantly challenging conventional methods used in genomics.\nIn parallel with the urgent demand for robust algorithms, deep learning has\nsucceeded in a variety of fields such as vision, speech, and text processing.\nYet genomics entails unique challenges to deep learning since we are expecting\nfrom deep learning a superhuman intelligence that explores beyond our knowledge\nto interpret the genome. A powerful deep learning model should rely on\ninsightful utilization of task-specific knowledge. In this paper, we briefly\ndiscuss the strengths of different deep learning models from a genomic\nperspective so as to fit each particular task with a proper deep architecture,\nand remark on practical considerations of developing modern deep learning\narchitectures for genomics. We also provide a concise review of deep learning\napplications in various aspects of genomic research, as well as pointing out\npotential opportunities and obstacles for future genomics applications.",
    "pdf_link": "http://arxiv.org/pdf/1802.00810v4.pdf",
    "authors": [
      "Tianwei Yue",
      "Yuanxin Wang",
      "Longxiang Zhang",
      "Chunming Gu",
      "Haoru Xue",
      "Wenping Wang",
      "Qi Lyu",
      "Yujie Dun"
    ]
  },
  {
    "title": "Adversarial Attack Based Countermeasures against Deep Learning\n  Side-Channel Attacks",
    "text": "Adversarial Attack Based Countermeasures against Deep Learning\n  Side-Channel Attacks. Numerous previous works have studied deep learning algorithms applied in the\ncontext of side-channel attacks, which demonstrated the ability to perform\nsuccessful key recoveries. These studies show that modern cryptographic devices\nare increasingly threatened by side-channel attacks with the help of deep\nlearning. However, the existing countermeasures are designed to resist\nclassical side-channel attacks, and cannot protect cryptographic devices from\ndeep learning based side-channel attacks. Thus, there arises a strong need for\ncountermeasures against deep learning based side-channel attacks. Although deep\nlearning has the high potential in solving complex problems, it is vulnerable\nto adversarial attacks in the form of subtle perturbations to inputs that lead\na model to predict incorrectly.\n  In this paper, we propose a kind of novel countermeasures based on\nadversarial attacks that is specifically designed against deep learning based\nside-channel attacks. We estimate several models commonly used in deep learning\nbased side-channel attacks to evaluate the proposed countermeasures. It shows\nthat our approach can effectively protect cryptographic devices from deep\nlearning based side-channel attacks in practice. In addition, our experiments\nshow that the new countermeasures can also resist classical side-channel\nattacks.",
    "pdf_link": "http://arxiv.org/pdf/2009.10568v1.pdf",
    "authors": [
      "Ruizhe Gu",
      "Ping Wang",
      "Mengce Zheng",
      "Honggang Hu",
      "Nenghai Yu"
    ]
  },
  {
    "title": "Accelerating Deep Learning with Shrinkage and Recall",
    "text": "Accelerating Deep Learning with Shrinkage and Recall. Deep Learning is a very powerful machine learning model. Deep Learning trains\na large number of parameters for multiple layers and is very slow when data is\nin large scale and the architecture size is large. Inspired from the shrinking\ntechnique used in accelerating computation of Support Vector Machines (SVM)\nalgorithm and screening technique used in LASSO, we propose a shrinking Deep\nLearning with recall (sDLr) approach to speed up deep learning computation. We\nexperiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network\n(DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data\nsets. Results show that the speedup using shrinking Deep Learning with recall\n(sDLr) can reach more than 2.0 while still giving competitive classification\nperformance.",
    "pdf_link": "http://arxiv.org/pdf/1605.01369v2.pdf",
    "authors": [
      "Shuai Zheng",
      "Abhinav Vishnu",
      "Chris Ding"
    ]
  },
  {
    "title": "Adversarial Robustness of Deep Learning: Theory, Algorithms, and\n  Applications",
    "text": "Adversarial Robustness of Deep Learning: Theory, Algorithms, and\n  Applications. This tutorial aims to introduce the fundamentals of adversarial robustness of\ndeep learning, presenting a well-structured review of up-to-date techniques to\nassess the vulnerability of various types of deep learning models to\nadversarial examples. This tutorial will particularly highlight\nstate-of-the-art techniques in adversarial attacks and robustness verification\nof deep neural networks (DNNs). We will also introduce some effective\ncountermeasures to improve the robustness of deep learning models, with a\nparticular focus on adversarial training. We aim to provide a comprehensive\noverall picture about this emerging direction and enable the community to be\naware of the urgency and importance of designing robust deep learning models in\nsafety-critical data analytical applications, ultimately enabling the end-users\nto trust deep learning classifiers. We will also summarize potential research\ndirections concerning the adversarial robustness of deep learning, and its\npotential benefits to enable accountable and trustworthy deep learning-based\ndata analytical systems and applications.",
    "pdf_link": "http://arxiv.org/pdf/2108.10451v1.pdf",
    "authors": [
      "Wenjie Ruan",
      "Xinping Yi",
      "Xiaowei Huang"
    ]
  },
  {
    "title": "Efficient Deep Feature Learning and Extraction via StochasticNets",
    "text": "Efficient Deep Feature Learning and Extraction via StochasticNets. Deep neural networks are a powerful tool for feature learning and extraction\ngiven their ability to model high-level abstractions in highly complex data.\nOne area worth exploring in feature learning and extraction using deep neural\nnetworks is efficient neural connectivity formation for faster feature learning\nand extraction. Motivated by findings of stochastic synaptic connectivity\nformation in the brain as well as the brain's uncanny ability to efficiently\nrepresent information, we propose the efficient learning and extraction of\nfeatures via StochasticNets, where sparsely-connected deep neural networks can\nbe formed via stochastic connectivity between neurons. To evaluate the\nfeasibility of such a deep neural network architecture for feature learning and\nextraction, we train deep convolutional StochasticNets to learn abstract\nfeatures using the CIFAR-10 dataset, and extract the learned features from\nimages to perform classification on the SVHN and STL-10 datasets. Experimental\nresults show that features learned using deep convolutional StochasticNets,\nwith fewer neural connections than conventional deep convolutional neural\nnetworks, can allow for better or comparable classification accuracy than\nconventional deep neural networks: relative test error decrease of ~4.5% for\nclassification on the STL-10 dataset and ~1% for classification on the SVHN\ndataset. Furthermore, it was shown that the deep features extracted using deep\nconvolutional StochasticNets can provide comparable classification accuracy\neven when only 10% of the training data is used for feature learning. Finally,\nit was also shown that significant gains in feature extraction speed can be\nachieved in embedded applications using StochasticNets. As such, StochasticNets\nallow for faster feature learning and extraction performance while facilitate\nfor better or comparable accuracy performances.",
    "pdf_link": "http://arxiv.org/pdf/1512.03844v1.pdf",
    "authors": [
      "Mohammad Javad Shafiee",
      "Parthipan Siva",
      "Paul Fieguth",
      "Alexander Wong"
    ]
  },
  {
    "title": "Modern Deep Reinforcement Learning Algorithms",
    "text": "Modern Deep Reinforcement Learning Algorithms. Recent advances in Reinforcement Learning, grounded on combining classical\ntheoretical results with Deep Learning paradigm, led to breakthroughs in many\nartificial intelligence tasks and gave birth to Deep Reinforcement Learning\n(DRL) as a field of research. In this work latest DRL algorithms are reviewed\nwith a focus on their theoretical justification, practical limitations and\nobserved empirical properties.",
    "pdf_link": "http://arxiv.org/pdf/1906.10025v2.pdf",
    "authors": [
      "Sergey Ivanov",
      "Alexander D'yakonov"
    ]
  },
  {
    "title": "An Essay on Optimization Mystery of Deep Learning",
    "text": "An Essay on Optimization Mystery of Deep Learning. Despite the huge empirical success of deep learning, theoretical\nunderstanding of neural networks learning process is still lacking. This is the\nreason, why some of its features seem \"mysterious\". We emphasize two mysteries\nof deep learning: generalization mystery, and optimization mystery. In this\nessay we review and draw connections between several selected works concerning\nthe latter.",
    "pdf_link": "http://arxiv.org/pdf/1905.07187v1.pdf",
    "authors": [
      "Eugene Golikov"
    ]
  },
  {
    "title": "Deep Super Learner: A Deep Ensemble for Classification Problems",
    "text": "Deep Super Learner: A Deep Ensemble for Classification Problems. Deep learning has become very popular for tasks such as predictive modeling\nand pattern recognition in handling big data. Deep learning is a powerful\nmachine learning method that extracts lower level features and feeds them\nforward for the next layer to identify higher level features that improve\nperformance. However, deep neural networks have drawbacks, which include many\nhyper-parameters and infinite architectures, opaqueness into results, and\nrelatively slower convergence on smaller datasets. While traditional machine\nlearning algorithms can address these drawbacks, they are not typically capable\nof the performance levels achieved by deep neural networks. To improve\nperformance, ensemble methods are used to combine multiple base learners. Super\nlearning is an ensemble that finds the optimal combination of diverse learning\nalgorithms. This paper proposes deep super learning as an approach which\nachieves log loss and accuracy results competitive to deep neural networks\nwhile employing traditional machine learning algorithms in a hierarchical\nstructure. The deep super learner is flexible, adaptable, and easy to train\nwith good performance across different tasks using identical hyper-parameter\nvalues. Using traditional machine learning requires fewer hyper-parameters,\nallows transparency into results, and has relatively fast convergence on\nsmaller datasets. Experimental results show that the deep super learner has\nsuperior performance compared to the individual base learners, single-layer\nensembles, and in some cases deep neural networks. Performance of the deep\nsuper learner may further be improved with task-specific tuning.",
    "pdf_link": "http://arxiv.org/pdf/1803.02323v1.pdf",
    "authors": [
      "Steven Young",
      "Tamer Abdou",
      "Ayse Bener"
    ]
  },
  {
    "title": "Deep Embedding Kernel",
    "text": "Deep Embedding Kernel. In this paper, we propose a novel supervised learning method that is called\nDeep Embedding Kernel (DEK). DEK combines the advantages of deep learning and\nkernel methods in a unified framework. More specifically, DEK is a learnable\nkernel represented by a newly designed deep architecture. Compared with\npre-defined kernels, this kernel can be explicitly trained to map data to an\noptimized high-level feature space where data may have favorable features\ntoward the application. Compared with typical deep learning using SoftMax or\nlogistic regression as the top layer, DEK is expected to be more generalizable\nto new data. Experimental results show that DEK has superior performance than\ntypical machine learning methods in identity detection, classification,\nregression, dimension reduction, and transfer learning.",
    "pdf_link": "http://arxiv.org/pdf/1804.05806v1.pdf",
    "authors": [
      "Linh Le",
      "Ying Xie"
    ]
  },
  {
    "title": "Priors in Bayesian Deep Learning: A Review",
    "text": "Priors in Bayesian Deep Learning: A Review. While the choice of prior is one of the most critical parts of the Bayesian\ninference workflow, recent Bayesian deep learning models have often fallen back\non vague priors, such as standard Gaussians. In this review, we highlight the\nimportance of prior choices for Bayesian deep learning and present an overview\nof different priors that have been proposed for (deep) Gaussian processes,\nvariational autoencoders, and Bayesian neural networks. We also outline\ndifferent methods of learning priors for these models from data. We hope to\nmotivate practitioners in Bayesian deep learning to think more carefully about\nthe prior specification for their models and to provide them with some\ninspiration in this regard.",
    "pdf_link": "http://arxiv.org/pdf/2105.06868v3.pdf",
    "authors": [
      "Vincent Fortuin"
    ]
  }
]