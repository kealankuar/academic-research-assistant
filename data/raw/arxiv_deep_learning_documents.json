[
  {
    "title": "Opening the black box of deep learning",
    "text": "Opening the black box of deep learning. The great success of deep learning shows that its technology contains\nprofound truth, and understanding its internal mechanism not only has important\nimplications for the development of its technology and effective application in\nvarious fields, but also provides meaningful insights into the understanding of\nhuman brain mechanism. At present, most of the theoretical research on deep\nlearning is based on mathematics. This dissertation proposes that the neural\nnetwork of deep learning is a physical system, examines deep learning from\nthree different perspectives: microscopic, macroscopic, and physical world\nviews, answers multiple theoretical puzzles in deep learning by using physics\nprinciples. For example, from the perspective of quantum mechanics and\nstatistical physics, this dissertation presents the calculation methods for\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\nMachine, as well as the selection of cost functions, explains why deep learning\nmust be deep, what characteristics are learned in deep learning, why\nConvolutional Neural Networks do not have to be trained layer by layer, and the\nlimitations of deep learning, etc., and proposes the theoretical direction and\nbasis for the further development of deep learning now and in the future. The\nbrilliance of physics flashes in deep learning, we try to establish the deep\nlearning technology based on the scientific theory of physics.",
    "pdf_link": "http://arxiv.org/pdf/1805.08355v1.pdf",
    "authors": [
      "Dian Lei",
      "Xiaoxiao Chen",
      "Jianfei Zhao"
    ]
  },
  {
    "title": "Deep learning research landscape & roadmap in a nutshell: past, present\n  and future -- Towards deep cortical learning",
    "text": "Deep learning research landscape & roadmap in a nutshell: past, present\n  and future -- Towards deep cortical learning. The past, present and future of deep learning is presented in this work.\nGiven this landscape & roadmap, we predict that deep cortical learning will be\nthe convergence of deep learning & cortical learning which builds an artificial\ncortical column ultimately.",
    "pdf_link": "http://arxiv.org/pdf/1908.02130v1.pdf",
    "authors": [
      "Aras R. Dargazany"
    ]
  },
  {
    "title": "Concept-Oriented Deep Learning",
    "text": "Concept-Oriented Deep Learning. Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.",
    "pdf_link": "http://arxiv.org/pdf/1806.01756v1.pdf",
    "authors": [
      "Daniel T Chang"
    ]
  },
  {
    "title": "A First Look at Deep Learning Apps on Smartphones",
    "text": "A First Look at Deep Learning Apps on Smartphones. We are in the dawn of deep learning explosion for smartphones. To bridge the\ngap between research and practice, we present the first empirical study on\n16,500 the most popular Android apps, demystifying how smartphone apps exploit\ndeep learning in the wild. To this end, we build a new static tool that\ndissects apps and analyzes their deep learning functions. Our study answers\nthreefold questions: what are the early adopter apps of deep learning, what do\nthey use deep learning for, and how do their deep learning models look like.\nOur study has strong implications for app developers, smartphone vendors, and\ndeep learning R\\&D. On one hand, our findings paint a promising picture of deep\nlearning for smartphones, showing the prosperity of mobile deep learning\nframeworks as well as the prosperity of apps building their cores atop deep\nlearning. On the other hand, our findings urge optimizations on deep learning\nmodels deployed on smartphones, the protection of these models, and validation\nof research ideas on these models.",
    "pdf_link": "http://arxiv.org/pdf/1812.05448v4.pdf",
    "authors": [
      "Mengwei Xu",
      "Jiawei Liu",
      "Yuanqiang Liu",
      "Felix Xiaozhu Lin",
      "Yunxin Liu",
      "Xuanzhe Liu"
    ]
  },
  {
    "title": "Geometrization of deep networks for the interpretability of deep\n  learning systems",
    "text": "Geometrization of deep networks for the interpretability of deep\n  learning systems. How to understand deep learning systems remains an open problem. In this\npaper we propose that the answer may lie in the geometrization of deep\nnetworks. Geometrization is a bridge to connect physics, geometry, deep network\nand quantum computation and this may result in a new scheme to reveal the rule\nof the physical world. By comparing the geometry of image matching and deep\nnetworks, we show that geometrization of deep networks can be used to\nunderstand existing deep learning systems and it may also help to solve the\ninterpretability problem of deep learning systems.",
    "pdf_link": "http://arxiv.org/pdf/1901.02354v2.pdf",
    "authors": [
      "Xiao Dong",
      "Ling Zhou"
    ]
  },
  {
    "title": "Why & When Deep Learning Works: Looking Inside Deep Learnings",
    "text": "Why & When Deep Learning Works: Looking Inside Deep Learnings. The Intel Collaborative Research Institute for Computational Intelligence\n(ICRI-CI) has been heavily supporting Machine Learning and Deep Learning\nresearch from its foundation in 2012. We have asked six leading ICRI-CI Deep\nLearning researchers to address the challenge of \"Why & When Deep Learning\nworks\", with the goal of looking inside Deep Learning, providing insights on\nhow deep networks function, and uncovering key observations on their\nexpressiveness, limitations, and potential. The output of this challenge\nresulted in five papers that address different facets of deep learning. These\ndifferent facets include a high-level understating of why and when deep\nnetworks work (and do not work), the impact of geometry on the expressiveness\nof deep networks, and making deep networks interpretable.",
    "pdf_link": "http://arxiv.org/pdf/1705.03921v1.pdf",
    "authors": [
      "Ronny Ronen"
    ]
  },
  {
    "title": "Learning Task-aware Robust Deep Learning Systems",
    "text": "Learning Task-aware Robust Deep Learning Systems. Many works demonstrate that deep learning system is vulnerable to adversarial\nattack. A deep learning system consists of two parts: the deep learning task\nand the deep model. Nowadays, most existing works investigate the impact of the\ndeep model on robustness of deep learning systems, ignoring the impact of the\nlearning task. In this paper, we adopt the binary and interval label encoding\nstrategy to redefine the classification task and design corresponding loss to\nimprove robustness of the deep learning system. Our method can be viewed as\nimproving the robustness of deep learning systems from both the learning task\nand deep model. Experimental results demonstrate that our learning task-aware\nmethod is much more robust than traditional classification while retaining the\naccuracy.",
    "pdf_link": "http://arxiv.org/pdf/2010.05125v2.pdf",
    "authors": [
      "Keji Han",
      "Yun Li",
      "Xianzhong Long",
      "Yao Ge"
    ]
  },
  {
    "title": "Deep Learning in Software Engineering",
    "text": "Deep Learning in Software Engineering. Recent years, deep learning is increasingly prevalent in the field of\nSoftware Engineering (SE). However, many open issues still remain to be\ninvestigated. How do researchers integrate deep learning into SE problems?\nWhich SE phases are facilitated by deep learning? Do practitioners benefit from\ndeep learning? The answers help practitioners and researchers develop practical\ndeep learning models for SE tasks. To answer these questions, we conduct a\nbibliography analysis on 98 research papers in SE that use deep learning\ntechniques. We find that 41 SE tasks in all SE phases have been facilitated by\ndeep learning integrated solutions. In which, 84.7% papers only use standard\ndeep learning models and their variants to solve SE problems. The\npracticability becomes a concern in utilizing deep learning techniques. How to\nimprove the effectiveness, efficiency, understandability, and testability of\ndeep learning based solutions may attract more SE researchers in the future.",
    "pdf_link": "http://arxiv.org/pdf/1805.04825v1.pdf",
    "authors": [
      "Xiaochen Li",
      "He Jiang",
      "Zhilei Ren",
      "Ge Li",
      "Jingxuan Zhang"
    ]
  },
  {
    "title": "Moving Deep Learning into Web Browser: How Far Can We Go?",
    "text": "Moving Deep Learning into Web Browser: How Far Can We Go?. Recently, several JavaScript-based deep learning frameworks have emerged,\nmaking it possible to perform deep learning tasks directly in browsers.\nHowever, little is known on what and how well we can do with these frameworks\nfor deep learning in browsers. To bridge the knowledge gap, in this paper, we\nconduct the first empirical study of deep learning in browsers. We survey 7\nmost popular JavaScript-based deep learning frameworks, investigating to what\nextent deep learning tasks have been supported in browsers so far. Then we\nmeasure the performance of different frameworks when running different deep\nlearning tasks. Finally, we dig out the performance gap between deep learning\nin browsers and on native platforms by comparing the performance of\nTensorFlow.js and TensorFlow in Python. Our findings could help application\ndevelopers, deep-learning framework vendors and browser vendors to improve the\nefficiency of deep learning in browsers.",
    "pdf_link": "http://arxiv.org/pdf/1901.09388v2.pdf",
    "authors": [
      "Yun Ma",
      "Dongwei Xiang",
      "Shuyu Zheng",
      "Deyu Tian",
      "Xuanzhe Liu"
    ]
  },
  {
    "title": "Greedy Deep Dictionary Learning",
    "text": "Greedy Deep Dictionary Learning. In this work we propose a new deep learning tool called deep dictionary\nlearning. Multi-level dictionaries are learnt in a greedy fashion, one layer at\na time. This requires solving a simple (shallow) dictionary learning problem,\nthe solution to this is well known. We apply the proposed technique on some\nbenchmark deep learning datasets. We compare our results with other deep\nlearning tools like stacked autoencoder and deep belief network; and state of\nthe art supervised dictionary learning tools like discriminative KSVD and label\nconsistent KSVD. Our method yields better results than all.",
    "pdf_link": "http://arxiv.org/pdf/1602.00203v1.pdf",
    "authors": [
      "Snigdha Tariyal",
      "Angshul Majumdar",
      "Richa Singh",
      "Mayank Vatsa"
    ]
  },
  {
    "title": "Quantum Neural Networks: Concepts, Applications, and Challenges",
    "text": "Quantum Neural Networks: Concepts, Applications, and Challenges. Quantum deep learning is a research field for the use of quantum computing\ntechniques for training deep neural networks. The research topics and\ndirections of deep learning and quantum computing have been separated for long\ntime, however by discovering that quantum circuits can act like artificial\nneural networks, quantum deep learning research is widely adopted. This paper\nexplains the backgrounds and basic principles of quantum deep learning and also\nintroduces major achievements. After that, this paper discusses the challenges\nof quantum deep learning research in multiple perspectives. Lastly, this paper\npresents various future research directions and application fields of quantum\ndeep learning.",
    "pdf_link": "http://arxiv.org/pdf/2108.01468v1.pdf",
    "authors": [
      "Yunseok Kwak",
      "Won Joon Yun",
      "Soyi Jung",
      "Joongheon Kim"
    ]
  },
  {
    "title": "NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders\n  of Deep Giants",
    "text": "NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders\n  of Deep Giants. Tiny deep learning has attracted increasing attention driven by the\nsubstantial demand for deploying deep learning on numerous intelligent\nInternet-of-Things devices. However, it is still challenging to unleash tiny\ndeep learning's full potential on both large-scale datasets and downstream\ntasks due to the under-fitting issues caused by the limited model capacity of\ntiny neural networks (TNNs). To this end, we propose a framework called\nNetBooster to empower tiny deep learning by augmenting the architectures of\nTNNs via an expansion-then-contraction strategy. Extensive experiments show\nthat NetBooster consistently outperforms state-of-the-art tiny deep learning\nsolutions.",
    "pdf_link": "http://arxiv.org/pdf/2306.13586v1.pdf",
    "authors": [
      "Zhongzhi Yu",
      "Yonggan Fu",
      "Jiayi Yuan",
      "Haoran You",
      "Yingyan Lin"
    ]
  },
  {
    "title": "Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey",
    "text": "Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey. Deep reinforcement learning augments the reinforcement learning framework and\nutilizes the powerful representation of deep neural networks. Recent works have\ndemonstrated the remarkable successes of deep reinforcement learning in various\ndomains including finance, medicine, healthcare, video games, robotics, and\ncomputer vision. In this work, we provide a detailed review of recent and\nstate-of-the-art research advances of deep reinforcement learning in computer\nvision. We start with comprehending the theories of deep learning,\nreinforcement learning, and deep reinforcement learning. We then propose a\ncategorization of deep reinforcement learning methodologies and discuss their\nadvantages and limitations. In particular, we divide deep reinforcement\nlearning into seven main categories according to their applications in computer\nvision, i.e. (i)landmark localization (ii) object detection; (iii) object\ntracking; (iv) registration on both 2D image and 3D image volumetric data (v)\nimage segmentation; (vi) videos analysis; and (vii) other applications. Each of\nthese categories is further analyzed with reinforcement learning techniques,\nnetwork design, and performance. Moreover, we provide a comprehensive analysis\nof the existing publicly available datasets and examine source code\navailability. Finally, we present some open issues and discuss future research\ndirections on deep reinforcement learning in computer vision",
    "pdf_link": "http://arxiv.org/pdf/2108.11510v1.pdf",
    "authors": [
      "Ngan Le",
      "Vidhiwar Singh Rathour",
      "Kashu Yamazaki",
      "Khoa Luu",
      "Marios Savvides"
    ]
  },
  {
    "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep\n  Probabilistic Models",
    "text": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep\n  Probabilistic Models. Probabilistic deep learning is deep learning that accounts for uncertainty,\nboth model uncertainty and data uncertainty. It is based on the use of\nprobabilistic models and deep neural networks. We distinguish two approaches to\nprobabilistic deep learning: probabilistic neural networks and deep\nprobabilistic models. The former employs deep neural networks that utilize\nprobabilistic layers which can represent and process uncertainty; the latter\nuses probabilistic models that incorporate deep neural network components which\ncapture complex non-linear stochastic relationships between the random\nvariables. We discuss some major examples of each approach including Bayesian\nneural networks and mixture density networks (for probabilistic neural\nnetworks), and variational autoencoders, deep Gaussian processes and deep mixed\neffects models (for deep probabilistic models). TensorFlow Probability is a\nlibrary for probabilistic modeling and inference which can be used for both\napproaches of probabilistic deep learning. We include its code examples for\nillustration.",
    "pdf_link": "http://arxiv.org/pdf/2106.00120v3.pdf",
    "authors": [
      "Daniel T. Chang"
    ]
  },
  {
    "title": "Towards energy-efficient Deep Learning: An overview of energy-efficient\n  approaches along the Deep Learning Lifecycle",
    "text": "Towards energy-efficient Deep Learning: An overview of energy-efficient\n  approaches along the Deep Learning Lifecycle. Deep Learning has enabled many advances in machine learning applications in\nthe last few years. However, since current Deep Learning algorithms require\nmuch energy for computations, there are growing concerns about the associated\nenvironmental costs. Energy-efficient Deep Learning has received much attention\nfrom researchers and has already made much progress in the last couple of\nyears. This paper aims to gather information about these advances from the\nliterature and show how and at which points along the lifecycle of Deep\nLearning (IT-Infrastructure, Data, Modeling, Training, Deployment, Evaluation)\nit is possible to reduce energy consumption.",
    "pdf_link": "http://arxiv.org/pdf/2303.01980v1.pdf",
    "authors": [
      "Vanessa Mehlin",
      "Sigurd Schacht",
      "Carsten Lanquillon"
    ]
  },
  {
    "title": "A Unified Framework of Deep Neural Networks by Capsules",
    "text": "A Unified Framework of Deep Neural Networks by Capsules. With the growth of deep learning, how to describe deep neural networks\nunifiedly is becoming an important issue. We first formalize neural networks\nmathematically with their directed graph representations, and prove a\ngeneration theorem about the induced networks of connected directed acyclic\ngraphs. Then, we set up a unified framework for deep learning with capsule\nnetworks. This capsule framework could simplify the description of existing\ndeep neural networks, and provide a theoretical basis of graphic designing and\nprogramming techniques for deep learning models, thus would be of great\nsignificance to the advancement of deep learning.",
    "pdf_link": "http://arxiv.org/pdf/1805.03551v2.pdf",
    "authors": [
      "Yujian Li",
      "Chuanhui Shan"
    ]
  },
  {
    "title": "Integrating Learning and Reasoning with Deep Logic Models",
    "text": "Integrating Learning and Reasoning with Deep Logic Models. Deep learning is very effective at jointly learning feature representations\nand classification models, especially when dealing with high dimensional input\npatterns. Probabilistic logic reasoning, on the other hand, is capable to take\nconsistent and robust decisions in complex environments. The integration of\ndeep learning and logic reasoning is still an open-research problem and it is\nconsidered to be the key for the development of real intelligent agents. This\npaper presents Deep Logic Models, which are deep graphical models integrating\ndeep learning and logic reasoning both for learning and inference. Deep Logic\nModels create an end-to-end differentiable architecture, where deep learners\nare embedded into a network implementing a continuous relaxation of the logic\nknowledge. The learning process allows to jointly learn the weights of the deep\nlearners and the meta-parameters controlling the high-level reasoning. The\nexperimental results show that the proposed methodology overtakes the\nlimitations of the other approaches that have been proposed to bridge deep\nlearning and reasoning.",
    "pdf_link": "http://arxiv.org/pdf/1901.04195v1.pdf",
    "authors": [
      "Giuseppe Marra",
      "Francesco Giannini",
      "Michelangelo Diligenti",
      "Marco Gori"
    ]
  },
  {
    "title": "Deep Learning in the Field of Biometric Template Protection: An Overview",
    "text": "Deep Learning in the Field of Biometric Template Protection: An Overview. Today, deep learning represents the most popular and successful form of\nmachine learning. Deep learning has revolutionised the field of pattern\nrecognition, including biometric recognition. Biometric systems utilising deep\nlearning have been shown to achieve auspicious recognition accuracy, surpassing\nhuman performance. Apart from said breakthrough advances in terms of biometric\nperformance, the use of deep learning was reported to impact different\ncovariates of biometrics such as algorithmic fairness, vulnerability to\nattacks, or template protection. Technologies of biometric template protection\nare designed to enable a secure and privacy-preserving deployment of\nbiometrics. In the recent past, deep learning techniques have been frequently\napplied in biometric template protection systems for various purposes. This\nwork provides an overview of how advances in deep learning take influence on\nthe field of biometric template protection. The interrelation between improved\nbiometric performance rates and security in biometric template protection is\nelaborated. Further, the use of deep learning for obtaining feature\nrepresentations that are suitable for biometric template protection is\ndiscussed. Novel methods that apply deep learning to achieve various goals of\nbiometric template protection are surveyed along with deep learning-based\nattacks.",
    "pdf_link": "http://arxiv.org/pdf/2303.02715v1.pdf",
    "authors": [
      "Christian Rathgeb",
      "Jascha Kolberg",
      "Andreas Uhl",
      "Christoph Busch"
    ]
  },
  {
    "title": "A Survey Analyzing Generalization in Deep Reinforcement Learning",
    "text": "A Survey Analyzing Generalization in Deep Reinforcement Learning. Reinforcement learning research obtained significant success and attention\nwith the utilization of deep neural networks to solve problems in high\ndimensional state or action spaces. While deep reinforcement learning policies\nare currently being deployed in many different fields from medical applications\nto large language models, there are still ongoing questions the field is trying\nto answer on the generalization capabilities of deep reinforcement learning\npolicies. In this paper, we will formalize and analyze generalization in deep\nreinforcement learning. We will explain the fundamental reasons why deep\nreinforcement learning policies encounter overfitting problems that limit their\ngeneralization capabilities. Furthermore, we will categorize and explain the\nmanifold solution approaches to increase generalization, and overcome\noverfitting in deep reinforcement learning policies. From exploration to\nadversarial analysis and from regularization to robustness our paper provides\nan analysis on a wide range of subfields within deep reinforcement learning\nwith a broad scope and in-depth view. We believe our study can provide a\ncompact guideline for the current advancements in deep reinforcement learning,\nand help to construct robust deep neural policies with higher generalization\nskills.",
    "pdf_link": "http://arxiv.org/pdf/2401.02349v2.pdf",
    "authors": [
      "Ezgi Korkmaz"
    ]
  },
  {
    "title": "Transferability in Deep Learning: A Survey",
    "text": "Transferability in Deep Learning: A Survey. The success of deep learning algorithms generally depends on large-scale\ndata, while humans appear to have inherent ability of knowledge transfer, by\nrecognizing and applying relevant knowledge from previous learning experiences\nwhen encountering and solving unseen tasks. Such an ability to acquire and\nreuse knowledge is known as transferability in deep learning. It has formed the\nlong-term quest towards making deep learning as data-efficient as human\nlearning, and has been motivating fruitful design of more powerful deep\nlearning algorithms. We present this survey to connect different isolated areas\nin deep learning with their relation to transferability, and to provide a\nunified and complete view to investigating transferability through the whole\nlifecycle of deep learning. The survey elaborates the fundamental goals and\nchallenges in parallel with the core principles and methods, covering recent\ncornerstones in deep architectures, pre-training, task adaptation and domain\nadaptation. This highlights unanswered questions on the appropriate objectives\nfor learning transferable knowledge and for adapting the knowledge to new tasks\nand domains, avoiding catastrophic forgetting and negative transfer. Finally,\nwe implement a benchmark and an open-source library, enabling a fair evaluation\nof deep learning methods in terms of transferability.",
    "pdf_link": "http://arxiv.org/pdf/2201.05867v1.pdf",
    "authors": [
      "Junguang Jiang",
      "Yang Shu",
      "Jianmin Wang",
      "Mingsheng Long"
    ]
  },
  {
    "title": "What Really is Deep Learning Doing?",
    "text": "What Really is Deep Learning Doing?. Deep learning has achieved a great success in many areas, from computer\nvision to natural language processing, to game playing, and much more. Yet,\nwhat deep learning is really doing is still an open question. There are a lot\nof works in this direction. For example, [5] tried to explain deep learning by\ngroup renormalization, and [6] tried to explain deep learning from the view of\nfunctional approximation. In order to address this very crucial question, here\nwe see deep learning from perspective of mechanical learning and learning\nmachine (see [1], [2]). From this particular angle, we can see deep learning\nmuch better and answer with confidence: What deep learning is really doing? why\nit works well, how it works, and how much data is necessary for learning. We\nalso will discuss advantages and disadvantages of deep learning at the end of\nthis work.",
    "pdf_link": "http://arxiv.org/pdf/1711.03577v1.pdf",
    "authors": [
      "Chuyu Xiong"
    ]
  },
  {
    "title": "Feature versus Raw Sequence: Deep Learning Comparative Study on\n  Predicting Pre-miRNA",
    "text": "Feature versus Raw Sequence: Deep Learning Comparative Study on\n  Predicting Pre-miRNA. Should we input known genome sequence features or input sequence itself in\ndeep learning framework? As deep learning more popular in various applications,\nresearchers often come to question whether to generate features or use raw\nsequences for deep learning. To answer this question, we study the prediction\naccuracy of precursor miRNA prediction of feature-based deep belief network and\nsequence-based convolution neural network. Tested on a variant of six-layer\nconvolution neural net and three-layer deep belief network, we find the raw\nsequence input based convolution neural network model performs similar or\nslightly better than feature based deep belief networks with best accuracy\nvalues of 0.995 and 0.990, respectively. Both the models outperform existing\nbenchmarks models. The results shows us that if provided large enough data,\nwell devised raw sequence based deep learning models can replace feature based\ndeep learning models. However, construction of well behaved deep learning model\ncan be very challenging. In cased features can be easily extracted,\nfeature-based deep learning models may be a better alternative.",
    "pdf_link": "http://arxiv.org/pdf/1710.06798v1.pdf",
    "authors": [
      "Jaya Thomas",
      "Sonia Thomas",
      "Lee Sael"
    ]
  },
  {
    "title": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player\n  Multi-Agent Learning Toolbox",
    "text": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player\n  Multi-Agent Learning Toolbox. With the breakthrough of AlphaGo, deep reinforcement learning becomes a\nrecognized technique for solving sequential decision-making problems. Despite\nits reputation, data inefficiency caused by its trial and error learning\nmechanism makes deep reinforcement learning hard to be practical in a wide\nrange of areas. Plenty of methods have been developed for sample efficient deep\nreinforcement learning, such as environment modeling, experience transfer, and\ndistributed modifications, amongst which, distributed deep reinforcement\nlearning has shown its potential in various applications, such as\nhuman-computer gaming, and intelligent transportation. In this paper, we\nconclude the state of this exciting field, by comparing the classical\ndistributed deep reinforcement learning methods, and studying important\ncomponents to achieve efficient distributed learning, covering single player\nsingle agent distributed deep reinforcement learning to the most complex\nmultiple players multiple agents distributed deep reinforcement learning.\nFurthermore, we review recently released toolboxes that help to realize\ndistributed deep reinforcement learning without many modifications of their\nnon-distributed versions. By analyzing their strengths and weaknesses, a\nmulti-player multi-agent distributed deep reinforcement learning toolbox is\ndeveloped and released, which is further validated on Wargame, a complex\nenvironment, showing usability of the proposed toolbox for multiple players and\nmultiple agents distributed deep reinforcement learning under complex games.\nFinally, we try to point out challenges and future trends, hoping this brief\nreview can provide a guide or a spark for researchers who are interested in\ndistributed deep reinforcement learning.",
    "pdf_link": "http://arxiv.org/pdf/2212.00253v1.pdf",
    "authors": [
      "Qiyue Yin",
      "Tongtong Yu",
      "Shengqi Shen",
      "Jun Yang",
      "Meijing Zhao",
      "Kaiqi Huang",
      "Bin Liang",
      "Liang Wang"
    ]
  },
  {
    "title": "Are Efficient Deep Representations Learnable?",
    "text": "Are Efficient Deep Representations Learnable?. Many theories of deep learning have shown that a deep network can require\ndramatically fewer resources to represent a given function compared to a\nshallow network. But a question remains: can these efficient representations be\nlearned using current deep learning techniques? In this work, we test whether\nstandard deep learning methods can in fact find the efficient representations\nposited by several theories of deep representation. Specifically, we train deep\nneural networks to learn two simple functions with known efficient solutions:\nthe parity function and the fast Fourier transform. We find that using\ngradient-based optimization, a deep network does not learn the parity function,\nunless initialized very close to a hand-coded exact solution. We also find that\na deep linear neural network does not learn the fast Fourier transform, even in\nthe best-case scenario of infinite training data, unless the weights are\ninitialized very close to the exact hand-coded solution. Our results suggest\nthat not every element of the class of compositional functions can be learned\nefficiently by a deep network, and further restrictions are necessary to\nunderstand what functions are both efficiently representable and learnable.",
    "pdf_link": "http://arxiv.org/pdf/1807.06399v1.pdf",
    "authors": [
      "Maxwell Nye",
      "Andrew Saxe"
    ]
  },
  {
    "title": "Deep Learning: A Critical Appraisal",
    "text": "Deep Learning: A Critical Appraisal. Although deep learning has historical roots going back decades, neither the\nterm \"deep learning\" nor the approach was popular just over five years ago,\nwhen the field was reignited by papers such as Krizhevsky, Sutskever and\nHinton's now classic (2012) deep network model of Imagenet. What has the field\ndiscovered in the five subsequent years? Against a background of considerable\nprogress in areas such as speech recognition, image recognition, and game\nplaying, and considerable enthusiasm in the popular press, I present ten\nconcerns for deep learning, and suggest that deep learning must be supplemented\nby other techniques if we are to reach artificial general intelligence.",
    "pdf_link": "http://arxiv.org/pdf/1801.00631v1.pdf",
    "authors": [
      "Gary Marcus"
    ]
  },
  {
    "title": "Deep Learning for Sentiment Analysis : A Survey",
    "text": "Deep Learning for Sentiment Analysis : A Survey. Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.",
    "pdf_link": "http://arxiv.org/pdf/1801.07883v2.pdf",
    "authors": [
      "Lei Zhang",
      "Shuai Wang",
      "Bing Liu"
    ]
  },
  {
    "title": "Deep Learning for Visual Navigation of Underwater Robots",
    "text": "Deep Learning for Visual Navigation of Underwater Robots. This paper aims to briefly survey deep learning methods for visual navigation\nof underwater robotics. The scope of this paper includes the visual perception\nof underwater robotics with deep learning methods, the available visual\nunderwater datasets, imitation learning, and reinforcement learning methods for\nnavigation. Additionally, relevant works will be categorized under the\nimitation learning or deep learning paradigm for underwater robots for clarity\nof the training methodologies in the current landscape. Literature that uses\ndeep learning algorithms to process non-visual data for underwater navigation\nwill not be considered, except as contrasting examples.",
    "pdf_link": "http://arxiv.org/pdf/2310.19495v1.pdf",
    "authors": [
      "M. Sunbeam"
    ]
  },
  {
    "title": "When deep learning meets security",
    "text": "When deep learning meets security. Deep learning is an emerging research field that has proven its effectiveness\ntowards deploying more efficient intelligent systems. Security, on the other\nhand, is one of the most essential issues in modern communication systems.\nRecently many papers have shown that using deep learning models can achieve\npromising results when applied to the security domain. In this work, we provide\nan overview for the recent studies that apply deep learning techniques to the\nfield of security.",
    "pdf_link": "http://arxiv.org/pdf/1807.04739v1.pdf",
    "authors": [
      "Majd Latah"
    ]
  },
  {
    "title": "Deep Causal Learning for Robotic Intelligence",
    "text": "Deep Causal Learning for Robotic Intelligence. This invited review discusses causal learning in the context of robotic\nintelligence. The paper introduced the psychological findings on causal\nlearning in human cognition, then it introduced the traditional statistical\nsolutions on causal discovery and causal inference. The paper reviewed recent\ndeep causal learning algorithms with a focus on their architectures and the\nbenefits of using deep nets and discussed the gap between deep causal learning\nand the needs of robotic intelligence.",
    "pdf_link": "http://arxiv.org/pdf/2212.12597v1.pdf",
    "authors": [
      "Yangming Li"
    ]
  },
  {
    "title": "Deep learning in radiology: an overview of the concepts and a survey of\n  the state of the art",
    "text": "Deep learning in radiology: an overview of the concepts and a survey of\n  the state of the art. Deep learning is a branch of artificial intelligence where networks of simple\ninterconnected units are used to extract patterns from data in order to solve\ncomplex problems. Deep learning algorithms have shown groundbreaking\nperformance in a variety of sophisticated tasks, especially those related to\nimages. They have often matched or exceeded human performance. Since the\nmedical field of radiology mostly relies on extracting useful information from\nimages, it is a very natural application area for deep learning, and research\nin this area has rapidly grown in recent years. In this article, we review the\nclinical reality of radiology and discuss the opportunities for application of\ndeep learning algorithms. We also introduce basic concepts of deep learning\nincluding convolutional neural networks. Then, we present a survey of the\nresearch in deep learning applied to radiology. We organize the studies by the\ntypes of specific tasks that they attempt to solve and review the broad range\nof utilized deep learning algorithms. Finally, we briefly discuss opportunities\nand challenges for incorporating deep learning in the radiology practice of the\nfuture.",
    "pdf_link": "http://arxiv.org/pdf/1802.08717v1.pdf",
    "authors": [
      "Maciej A. Mazurowski",
      "Mateusz Buda",
      "Ashirbani Saha",
      "Mustafa R. Bashir"
    ]
  },
  {
    "title": "A Selective Overview of Deep Learning",
    "text": "A Selective Overview of Deep Learning. Deep learning has arguably achieved tremendous success in recent years. In\nsimple words, deep learning uses the composition of many nonlinear functions to\nmodel the complex dependency between input features and labels. While neural\nnetworks have a long history, recent advances have greatly improved their\nperformance in computer vision, natural language processing, etc. From the\nstatistical and scientific perspective, it is natural to ask: What is deep\nlearning? What are the new characteristics of deep learning, compared with\nclassical methods? What are the theoretical foundations of deep learning? To\nanswer these questions, we introduce common neural network models (e.g.,\nconvolutional neural nets, recurrent neural nets, generative adversarial nets)\nand training techniques (e.g., stochastic gradient descent, dropout, batch\nnormalization) from a statistical point of view. Along the way, we highlight\nnew characteristics of deep learning (including depth and over-parametrization)\nand explain their practical and theoretical benefits. We also sample recent\nresults on theories of deep learning, many of which are only suggestive. While\na complete understanding of deep learning remains elusive, we hope that our\nperspectives and discussions serve as a stimulus for new statistical research.",
    "pdf_link": "http://arxiv.org/pdf/1904.05526v2.pdf",
    "authors": [
      "Jianqing Fan",
      "Cong Ma",
      "Yiqiao Zhong"
    ]
  },
  {
    "title": "A Survey on Deep Learning Methods for Robot Vision",
    "text": "A Survey on Deep Learning Methods for Robot Vision. Deep learning has allowed a paradigm shift in pattern recognition, from using\nhand-crafted features together with statistical classifiers to using\ngeneral-purpose learning procedures for learning data-driven representations,\nfeatures, and classifiers together. The application of this new paradigm has\nbeen particularly successful in computer vision, in which the development of\ndeep learning methods for vision applications has become a hot research topic.\nGiven that deep learning has already attracted the attention of the robot\nvision community, the main purpose of this survey is to address the use of deep\nlearning in robot vision. To achieve this, a comprehensive overview of deep\nlearning and its usage in computer vision is given, that includes a description\nof the most frequently used neural models and their main application areas.\nThen, the standard methodology and tools used for designing deep-learning based\nvision systems are presented. Afterwards, a review of the principal work using\ndeep learning in robot vision is presented, as well as current and future\ntrends related to the use of deep learning in robotics. This survey is intended\nto be a guide for the developers of robot vision systems.",
    "pdf_link": "http://arxiv.org/pdf/1803.10862v1.pdf",
    "authors": [
      "Javier Ruiz-del-Solar",
      "Patricio Loncomilla",
      "Naiomi Soto"
    ]
  },
  {
    "title": "Interpretations of Deep Learning by Forests and Haar Wavelets",
    "text": "Interpretations of Deep Learning by Forests and Haar Wavelets. This paper presents a basic property of region dividing of ReLU (rectified\nlinear unit) deep learning when new layers are successively added, by which two\nnew perspectives of interpreting deep learning are given. The first is related\nto decision trees and forests; we construct a deep learning structure\nequivalent to a forest in classification abilities, which means that certain\nkinds of ReLU deep learning can be considered as forests. The second\nperspective is that Haar wavelet represented functions can be approximated by\nReLU deep learning with arbitrary precision; and then a general conclusion of\nfunction approximation abilities of ReLU deep learning is given. Finally,\ngeneralize some of the conclusions of ReLU deep learning to the case of\nsigmoid-unit deep learning.",
    "pdf_link": "http://arxiv.org/pdf/1906.06706v7.pdf",
    "authors": [
      "Changcun Huang"
    ]
  },
  {
    "title": "A Brief Survey of Deep Reinforcement Learning",
    "text": "A Brief Survey of Deep Reinforcement Learning. Deep reinforcement learning is poised to revolutionise the field of AI and\nrepresents a step towards building autonomous systems with a higher level\nunderstanding of the visual world. Currently, deep learning is enabling\nreinforcement learning to scale to problems that were previously intractable,\nsuch as learning to play video games directly from pixels. Deep reinforcement\nlearning algorithms are also applied to robotics, allowing control policies for\nrobots to be learned directly from camera inputs in the real world. In this\nsurvey, we begin with an introduction to the general field of reinforcement\nlearning, then progress to the main streams of value-based and policy-based\nmethods. Our survey will cover central algorithms in deep reinforcement\nlearning, including the deep $Q$-network, trust region policy optimisation, and\nasynchronous advantage actor-critic. In parallel, we highlight the unique\nadvantages of deep neural networks, focusing on visual understanding via\nreinforcement learning. To conclude, we describe several current areas of\nresearch within the field.",
    "pdf_link": "http://arxiv.org/pdf/1708.05866v2.pdf",
    "authors": [
      "Kai Arulkumaran",
      "Marc Peter Deisenroth",
      "Miles Brundage",
      "Anil Anthony Bharath"
    ]
  },
  {
    "title": "Topological Deep Learning: A Review of an Emerging Paradigm",
    "text": "Topological Deep Learning: A Review of an Emerging Paradigm. Topological data analysis (TDA) provides insight into data shape. The\nsummaries obtained by these methods are principled global descriptions of\nmulti-dimensional data whilst exhibiting stable properties such as robustness\nto deformation and noise. Such properties are desirable in deep learning\npipelines but they are typically obtained using non-TDA strategies. This is\npartly caused by the difficulty of combining TDA constructs (e.g. barcode and\npersistence diagrams) with current deep learning algorithms. Fortunately, we\nare now witnessing a growth of deep learning applications embracing\ntopologically-guided components. In this survey, we review the nascent field of\ntopological deep learning by first revisiting the core concepts of TDA. We then\nexplore how the use of TDA techniques has evolved over time to support deep\nlearning frameworks, and how they can be integrated into different aspects of\ndeep learning. Furthermore, we touch on TDA usage for analyzing existing deep\nmodels; deep topological analytics. Finally, we discuss the challenges and\nfuture prospects of topological deep learning.",
    "pdf_link": "http://arxiv.org/pdf/2302.03836v1.pdf",
    "authors": [
      "Ali Zia",
      "Abdelwahed Khamis",
      "James Nichols",
      "Zeeshan Hayder",
      "Vivien Rolland",
      "Lars Petersson"
    ]
  },
  {
    "title": "Generalization and Expressivity for Deep Nets",
    "text": "Generalization and Expressivity for Deep Nets. Along with the rapid development of deep learning in practice, the\ntheoretical explanations for its success become urgent. Generalization and\nexpressivity are two widely used measurements to quantify theoretical behaviors\nof deep learning. The expressivity focuses on finding functions expressible by\ndeep nets but cannot be approximated by shallow nets with the similar number of\nneurons. It usually implies the large capacity. The generalization aims at\nderiving fast learning rate for deep nets. It usually requires small capacity\nto reduce the variance. Different from previous studies on deep learning,\npursuing either expressivity or generalization, we take both factors into\naccount to explore the theoretical advantages of deep nets. For this purpose,\nwe construct a deep net with two hidden layers possessing excellent\nexpressivity in terms of localized and sparse approximation. Then, utilizing\nthe well known covering number to measure the capacity, we find that deep nets\npossess excellent expressive power (measured by localized and sparse\napproximation) without enlarging the capacity of shallow nets. As a\nconsequence, we derive near optimal learning rates for implementing empirical\nrisk minimization (ERM) on the constructed deep nets. These results\ntheoretically exhibit the advantage of deep nets from learning theory\nviewpoints.",
    "pdf_link": "http://arxiv.org/pdf/1803.03772v2.pdf",
    "authors": [
      "Shao-Bo Lin"
    ]
  },
  {
    "title": "Deep Incremental Boosting",
    "text": "Deep Incremental Boosting. This paper introduces Deep Incremental Boosting, a new technique derived from\nAdaBoost, specifically adapted to work with Deep Learning methods, that reduces\nthe required training time and improves generalisation. We draw inspiration\nfrom Transfer of Learning approaches to reduce the start-up time to training\neach incremental Ensemble member. We show a set of experiments that outlines\nsome preliminary results on some common Deep Learning datasets and discuss the\npotential improvements Deep Incremental Boosting brings to traditional Ensemble\nmethods in Deep Learning.",
    "pdf_link": "http://arxiv.org/pdf/1708.03704v1.pdf",
    "authors": [
      "Alan Mosca",
      "George D Magoulas"
    ]
  },
  {
    "title": "Combining Deep Learning with Good Old-Fashioned Machine Learning",
    "text": "Combining Deep Learning with Good Old-Fashioned Machine Learning. We present a comprehensive, stacking-based framework for combining deep\nlearning with good old-fashioned machine learning, called Deep GOld. Our\nframework involves ensemble selection from 51 retrained pretrained deep\nnetworks as first-level models, and 10 machine-learning algorithms as\nsecond-level models. Enabled by today's state-of-the-art software tools and\nhardware platforms, Deep GOld delivers consistent improvement when tested on\nfour image-classification datasets: Fashion MNIST, CIFAR10, CIFAR100, and Tiny\nImageNet. Of 120 experiments, in all but 10 Deep GOld improved the original\nnetworks' performance.",
    "pdf_link": "http://arxiv.org/pdf/2207.03757v2.pdf",
    "authors": [
      "Moshe Sipper"
    ]
  },
  {
    "title": "Deep frequency principle towards understanding why deeper learning is\n  faster",
    "text": "Deep frequency principle towards understanding why deeper learning is\n  faster. Understanding the effect of depth in deep learning is a critical problem. In\nthis work, we utilize the Fourier analysis to empirically provide a promising\nmechanism to understand why feedforward deeper learning is faster. To this end,\nwe separate a deep neural network, trained by normal stochastic gradient\ndescent, into two parts during analysis, i.e., a pre-condition component and a\nlearning component, in which the output of the pre-condition one is the input\nof the learning one. We use a filtering method to characterize the frequency\ndistribution of a high-dimensional function. Based on experiments of deep\nnetworks and real dataset, we propose a deep frequency principle, that is, the\neffective target function for a deeper hidden layer biases towards lower\nfrequency during the training. Therefore, the learning component effectively\nlearns a lower frequency function if the pre-condition component has more\nlayers. Due to the well-studied frequency principle, i.e., deep neural networks\nlearn lower frequency functions faster, the deep frequency principle provides a\nreasonable explanation to why deeper learning is faster. We believe these\nempirical studies would be valuable for future theoretical studies of the\neffect of depth in deep learning.",
    "pdf_link": "http://arxiv.org/pdf/2007.14313v2.pdf",
    "authors": [
      "Zhi-Qin John Xu",
      "Hanxu Zhou"
    ]
  },
  {
    "title": "Deep Bayesian Active Learning with Image Data",
    "text": "Deep Bayesian Active Learning with Image Data. Even though active learning forms an important pillar of machine learning,\ndeep learning tools are not prevalent within it. Deep learning poses several\ndifficulties when used in an active learning setting. First, active learning\n(AL) methods generally rely on being able to learn and update models from small\namounts of data. Recent advances in deep learning, on the other hand, are\nnotorious for their dependence on large amounts of data. Second, many AL\nacquisition functions rely on model uncertainty, yet deep learning methods\nrarely represent such model uncertainty. In this paper we combine recent\nadvances in Bayesian deep learning into the active learning framework in a\npractical way. We develop an active learning framework for high dimensional\ndata, a task which has been extremely challenging so far, with very sparse\nexisting literature. Taking advantage of specialised models such as Bayesian\nconvolutional neural networks, we demonstrate our active learning techniques\nwith image data, obtaining a significant improvement on existing active\nlearning approaches. We demonstrate this on both the MNIST dataset, as well as\nfor skin cancer diagnosis from lesion images (ISIC2016 task).",
    "pdf_link": "http://arxiv.org/pdf/1703.02910v1.pdf",
    "authors": [
      "Yarin Gal",
      "Riashat Islam",
      "Zoubin Ghahramani"
    ]
  },
  {
    "title": "Deep reinforcement learning for optical systems: A case study of\n  mode-locked lasers",
    "text": "Deep reinforcement learning for optical systems: A case study of\n  mode-locked lasers. We demonstrate that deep reinforcement learning (deep RL) provides a highly\neffective strategy for the control and self-tuning of optical systems. Deep RL\nintegrates the two leading machine learning architectures of deep neural\nnetworks and reinforcement learning to produce robust and stable learning for\ncontrol. Deep RL is ideally suited for optical systems as the tuning and\ncontrol relies on interactions with its environment with a goal-oriented\nobjective to achieve optimal immediate or delayed rewards. This allows the\noptical system to recognize bi-stable structures and navigate, via trajectory\nplanning, to optimally performing solutions, the first such algorithm\ndemonstrated to do so in optical systems. We specifically demonstrate the deep\nRL architecture on a mode-locked laser, where robust self-tuning and control\ncan be established through access of the deep RL agent to its waveplates and\npolarizers. We further integrate transfer learning to help the deep RL agent\nrapidly learn new parameter regimes and generalize its control authority.\nAdditionally, the deep RL learning can be easily integrated with other control\nparadigms to provide a broad framework to control any optical system.",
    "pdf_link": "http://arxiv.org/pdf/2006.05579v1.pdf",
    "authors": [
      "Chang Sun",
      "Eurika Kaiser",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ]
  },
  {
    "title": "Error Bounds for a Matrix-Vector Product Approximation with Deep ReLU\n  Neural Networks",
    "text": "Error Bounds for a Matrix-Vector Product Approximation with Deep ReLU\n  Neural Networks. Among the several paradigms of artificial intelligence (AI) or machine\nlearning (ML), a remarkably successful paradigm is deep learning. Deep\nlearning's phenomenal success has been hoped to be interpreted via fundamental\nresearch on the theory of deep learning. Accordingly, applied research on deep\nlearning has spurred the theory of deep learning-oriented depth and breadth of\ndevelopments. Inspired by such developments, we pose these fundamental\nquestions: can we accurately approximate an arbitrary matrix-vector product\nusing deep rectified linear unit (ReLU) feedforward neural networks (FNNs)? If\nso, can we bound the resulting approximation error? In light of these\nquestions, we derive error bounds in Lebesgue and Sobolev norms that comprise\nour developed deep approximation theory. Guided by this theory, we have\nsuccessfully trained deep ReLU FNNs whose test results justify our developed\ntheory. The developed theory is also applicable for guiding and easing the\ntraining of teacher deep ReLU FNNs in view of the emerging teacher-student AI\nor ML paradigms that are essential for solving several AI or ML problems in\nwireless communications and signal processing; network science and graph signal\nprocessing; and network neuroscience and brain physics.",
    "pdf_link": "http://arxiv.org/pdf/2111.12963v1.pdf",
    "authors": [
      "Tilahun M. Getu"
    ]
  },
  {
    "title": "Joint Training of Deep Boltzmann Machines",
    "text": "Joint Training of Deep Boltzmann Machines. We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods require an initial learning pass that trains the deep Boltzmann machine\ngreedily, one layer at a time, or do not perform well on classifi- cation\ntasks.",
    "pdf_link": "http://arxiv.org/pdf/1212.2686v1.pdf",
    "authors": [
      "Ian Goodfellow",
      "Aaron Courville",
      "Yoshua Bengio"
    ]
  },
  {
    "title": "Introduction to deep learning",
    "text": "Introduction to deep learning. Deep Learning (DL) has made a major impact on data science in the last\ndecade. This chapter introduces the basic concepts of this field. It includes\nboth the basic structures used to design deep neural networks and a brief\nsurvey of some of its popular use cases.",
    "pdf_link": "http://arxiv.org/pdf/2003.03253v1.pdf",
    "authors": [
      "Lihi Shiloh-Perl",
      "Raja Giryes"
    ]
  },
  {
    "title": "Deep Learning: From Basics to Building Deep Neural Networks with Python",
    "text": "Deep Learning: From Basics to Building Deep Neural Networks with Python. This book is intended for beginners who have no familiarity with deep\nlearning. Our only expectation from readers is that they already have the basic\nprogramming skills in Python.",
    "pdf_link": "http://arxiv.org/pdf/2205.01069v1.pdf",
    "authors": [
      "Milad Vazan"
    ]
  },
  {
    "title": "A Nesterov's Accelerated quasi-Newton method for Global Routing using\n  Deep Reinforcement Learning",
    "text": "A Nesterov's Accelerated quasi-Newton method for Global Routing using\n  Deep Reinforcement Learning. Deep Q-learning method is one of the most popularly used deep reinforcement\nlearning algorithms which uses deep neural networks to approximate the\nestimation of the action-value function. Training of the deep Q-network (DQN)\nis usually restricted to first order gradient based methods. This paper\nattempts to accelerate the training of deep Q-networks by introducing a second\norder Nesterov's accelerated quasi-Newton method. We evaluate the performance\nof the proposed method on deep reinforcement learning using double DQNs for\nglobal routing. The results show that the proposed method can obtain better\nrouting solutions compared to the DQNs trained with first order Adam and\nRMSprop methods.",
    "pdf_link": "http://arxiv.org/pdf/2010.09465v1.pdf",
    "authors": [
      "S. Indrapriyadarsini",
      "Shahrzad Mahboubi",
      "Hiroshi Ninomiya",
      "Takeshi Kamio",
      "Hideki Asai"
    ]
  },
  {
    "title": "Augmented Q Imitation Learning (AQIL)",
    "text": "Augmented Q Imitation Learning (AQIL). The study of unsupervised learning can be generally divided into two\ncategories: imitation learning and reinforcement learning. In imitation\nlearning the machine learns by mimicking the behavior of an expert system\nwhereas in reinforcement learning the machine learns via direct environment\nfeedback. Traditional deep reinforcement learning takes a significant time\nbefore the machine starts to converge to an optimal policy. This paper proposes\nAugmented Q-Imitation-Learning, a method by which deep reinforcement learning\nconvergence can be accelerated by applying Q-imitation-learning as the initial\ntraining process in traditional Deep Q-learning.",
    "pdf_link": "http://arxiv.org/pdf/2004.00993v2.pdf",
    "authors": [
      "Xiao Lei Zhang",
      "Anish Agarwal"
    ]
  },
  {
    "title": "Deep Reinforcement Learning for Conversational AI",
    "text": "Deep Reinforcement Learning for Conversational AI. Deep reinforcement learning is revolutionizing the artificial intelligence\nfield. Currently, it serves as a good starting point for constructing\nintelligent autonomous systems which offer a better knowledge of the visual\nworld. It is possible to scale deep reinforcement learning with the use of deep\nlearning and do amazing tasks such as use of pixels in playing video games. In\nthis paper, key concepts of deep reinforcement learning including reward\nfunction, differences between reinforcement learning and supervised learning\nand models for implementation of reinforcement are discussed. Key challenges\nrelated to the implementation of reinforcement learning in conversational AI\ndomain are identified as well as discussed in detail. Various conversational\nmodels which are based on deep reinforcement learning (as well as deep\nlearning) are also discussed. In summary, this paper discusses key aspects of\ndeep reinforcement learning which are crucial for designing an efficient\nconversational AI.",
    "pdf_link": "http://arxiv.org/pdf/1709.05067v1.pdf",
    "authors": [
      "Mahipal Jadeja",
      "Neelanshi Varia",
      "Agam Shah"
    ]
  },
  {
    "title": "An Overview of Deep Semi-Supervised Learning",
    "text": "An Overview of Deep Semi-Supervised Learning. Deep neural networks demonstrated their ability to provide remarkable\nperformances on a wide range of supervised learning tasks (e.g., image\nclassification) when trained on extensive collections of labeled data (e.g.,\nImageNet). However, creating such large datasets requires a considerable amount\nof resources, time, and effort. Such resources may not be available in many\npractical cases, limiting the adoption and the application of many deep\nlearning methods. In a search for more data-efficient deep learning methods to\novercome the need for large annotated datasets, there is a rising research\ninterest in semi-supervised learning and its applications to deep neural\nnetworks to reduce the amount of labeled data required, by either developing\nnovel methods or adopting existing semi-supervised learning frameworks for a\ndeep learning setting. In this paper, we provide a comprehensive overview of\ndeep semi-supervised learning, starting with an introduction to the field,\nfollowed by a summarization of the dominant semi-supervised approaches in deep\nlearning.",
    "pdf_link": "http://arxiv.org/pdf/2006.05278v2.pdf",
    "authors": [
      "Yassine Ouali",
      "C\u00e9line Hudelot",
      "Myriam Tami"
    ]
  },
  {
    "title": "Node-By-Node Greedy Deep Learning for Interpretable Features",
    "text": "Node-By-Node Greedy Deep Learning for Interpretable Features. Multilayer networks have seen a resurgence under the umbrella of deep\nlearning. Current deep learning algorithms train the layers of the network\nsequentially, improving algorithmic performance as well as providing some\nregularization. We present a new training algorithm for deep networks which\ntrains \\emph{each node in the network} sequentially. Our algorithm is orders of\nmagnitude faster, creates more interpretable internal representations at the\nnode level, while not sacrificing on the ultimate out-of-sample performance.",
    "pdf_link": "http://arxiv.org/pdf/1602.06183v1.pdf",
    "authors": [
      "Ke Wu",
      "Malik Magdon-Ismail"
    ]
  }
]