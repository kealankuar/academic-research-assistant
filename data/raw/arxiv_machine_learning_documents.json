[
  {
    "title": "Lecture Notes: Optimization for Machine Learning",
    "text": "Lecture Notes: Optimization for Machine Learning. Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.",
    "pdf_link": "http://arxiv.org/pdf/1909.03550v1.pdf",
    "authors": [
      "Elad Hazan"
    ]
  },
  {
    "title": "An Optimal Control View of Adversarial Machine Learning",
    "text": "An Optimal Control View of Adversarial Machine Learning. I describe an optimal control view of adversarial machine learning, where the\ndynamical system is the machine learner, the input are adversarial actions, and\nthe control costs are defined by the adversary's goals to do harm and be hard\nto detect. This view encompasses many types of adversarial machine learning,\nincluding test-item attacks, training-data poisoning, and adversarial reward\nshaping. The view encourages adversarial machine learning researcher to utilize\nadvances in control theory and reinforcement learning.",
    "pdf_link": "http://arxiv.org/pdf/1811.04422v1.pdf",
    "authors": [
      "Xiaojin Zhu"
    ]
  },
  {
    "title": "Minimax deviation strategies for machine learning and recognition with\n  short learning samples",
    "text": "Minimax deviation strategies for machine learning and recognition with\n  short learning samples. The article is devoted to the problem of small learning samples in machine\nlearning. The flaws of maximum likelihood learning and minimax learning are\nlooked into and the concept of minimax deviation learning is introduced that is\nfree of those flaws.",
    "pdf_link": "http://arxiv.org/pdf/1707.04849v1.pdf",
    "authors": [
      "Michail Schlesinger",
      "Evgeniy Vodolazskiy"
    ]
  },
  {
    "title": "Machine Learning for Clinical Predictive Analytics",
    "text": "Machine Learning for Clinical Predictive Analytics. In this chapter, we provide a brief overview of applying machine learning\ntechniques for clinical prediction tasks. We begin with a quick introduction to\nthe concepts of machine learning and outline some of the most common machine\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\nappropriate toolkits to conduct machine learning experiments for clinical\nprediction tasks. The objectives of this chapter are to (1) understand the\nbasics of machine learning techniques and the reasons behind why they are\nuseful for solving clinical prediction problems, (2) understand the intuition\nbehind some machine learning models, including regression, decision trees, and\nsupport vector machines, and (3) understand how to apply these models to\nclinical prediction problems using publicly available datasets via case\nstudies.",
    "pdf_link": "http://arxiv.org/pdf/1909.09246v1.pdf",
    "authors": [
      "Wei-Hung Weng"
    ]
  },
  {
    "title": "Towards Modular Machine Learning Solution Development: Benefits and\n  Trade-offs",
    "text": "Towards Modular Machine Learning Solution Development: Benefits and\n  Trade-offs. Machine learning technologies have demonstrated immense capabilities in\nvarious domains. They play a key role in the success of modern businesses.\nHowever, adoption of machine learning technologies has a lot of untouched\npotential. Cost of developing custom machine learning solutions that solve\nunique business problems is a major inhibitor to far-reaching adoption of\nmachine learning technologies. We recognize that the monolithic nature\nprevalent in today's machine learning applications stands in the way of\nefficient and cost effective customized machine learning solution development.\nIn this work we explore the benefits of modular machine learning solutions and\ndiscuss how modular machine learning solutions can overcome some of the major\nsolution engineering limitations of monolithic machine learning solutions. We\nanalyze the trade-offs between modular and monolithic machine learning\nsolutions through three deep learning problems; one text based and the two\nimage based. Our experimental results show that modular machine learning\nsolutions have a promising potential to reap the solution engineering\nadvantages of modularity while gaining performance and data advantages in a way\nthe monolithic machine learning solutions do not permit.",
    "pdf_link": "http://arxiv.org/pdf/2301.09753v1.pdf",
    "authors": [
      "Samiyuru Menik",
      "Lakshmish Ramaswamy"
    ]
  },
  {
    "title": "Introduction to Machine Learning: Class Notes 67577",
    "text": "Introduction to Machine Learning: Class Notes 67577. Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).",
    "pdf_link": "http://arxiv.org/pdf/0904.3664v1.pdf",
    "authors": [
      "Amnon Shashua"
    ]
  },
  {
    "title": "The Tribes of Machine Learning and the Realm of Computer Architecture",
    "text": "The Tribes of Machine Learning and the Realm of Computer Architecture. Machine learning techniques have influenced the field of computer\narchitecture like many other fields. This paper studies how the fundamental\nmachine learning techniques can be applied towards computer architecture\nproblems. We also provide a detailed survey of computer architecture research\nthat employs different machine learning methods. Finally, we present some\nfuture opportunities and the outstanding challenges that need to be overcome to\nexploit full potential of machine learning for computer architecture.",
    "pdf_link": "http://arxiv.org/pdf/2012.04105v1.pdf",
    "authors": [
      "Ayaz Akram",
      "Jason Lowe-Power"
    ]
  },
  {
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part I:\n  Traditional Machine Learning",
    "text": "A Machine Learning Tutorial for Operational Meteorology, Part I:\n  Traditional Machine Learning. Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.",
    "pdf_link": "http://arxiv.org/pdf/2204.07492v2.pdf",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Amanda Burke",
      "Gary M. Lackmann",
      "Amy McGovern"
    ]
  },
  {
    "title": "Position Paper: Towards Transparent Machine Learning",
    "text": "Position Paper: Towards Transparent Machine Learning. Transparent machine learning is introduced as an alternative form of machine\nlearning, where both the model and the learning system are represented in\nsource code form. The goal of this project is to enable direct human\nunderstanding of machine learning models, giving us the ability to learn,\nverify, and refine them as programs. If solved, this technology could represent\na best-case scenario for the safety and security of AI systems going forward.",
    "pdf_link": "http://arxiv.org/pdf/1911.06612v1.pdf",
    "authors": [
      "Dustin Juliano"
    ]
  },
  {
    "title": "Understanding Bias in Machine Learning",
    "text": "Understanding Bias in Machine Learning. Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.",
    "pdf_link": "http://arxiv.org/pdf/1909.01866v1.pdf",
    "authors": [
      "Jindong Gu",
      "Daniela Oelke"
    ]
  },
  {
    "title": "A Unified Analytical Framework for Trustable Machine Learning and\n  Automation Running with Blockchain",
    "text": "A Unified Analytical Framework for Trustable Machine Learning and\n  Automation Running with Blockchain. Traditional machine learning algorithms use data from databases that are\nmutable, and therefore the data cannot be fully trusted. Also, the machine\nlearning process is difficult to automate. This paper proposes building a\ntrustable machine learning system by using blockchain technology, which can\nstore data in a permanent and immutable way. In addition, smart contracts are\nused to automate the machine learning process. This paper makes three\ncontributions. First, it establishes a link between machine learning technology\nand blockchain technology. Previously, machine learning and blockchain have\nbeen considered two independent technologies without an obvious link. Second,\nit proposes a unified analytical framework for trustable machine learning by\nusing blockchain technology. This unified framework solves both the\ntrustability and automation issues in machine learning. Third, it enables a\ncomputer to translate core machine learning implementation from a single thread\non a single machine to multiple threads on multiple machines running with\nblockchain by using a unified approach. The paper uses association rule mining\nas an example to demonstrate how trustable machine learning can be implemented\nwith blockchain, and it shows how this approach can be used to analyze opioid\nprescriptions to help combat the opioid crisis.",
    "pdf_link": "http://arxiv.org/pdf/1903.08801v1.pdf",
    "authors": [
      "Tao Wang"
    ]
  },
  {
    "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification\n  Tasks on Structured Data?",
    "text": "MLBench: How Good Are Machine Learning Clouds for Binary Classification\n  Tasks on Structured Data?. We conduct an empirical study of machine learning functionalities provided by\nmajor cloud service providers, which we call machine learning clouds. Machine\nlearning clouds hold the promise of hiding all the sophistication of running\nlarge-scale machine learning: Instead of specifying how to run a machine\nlearning task, users only specify what machine learning task to run and the\ncloud figures out the rest. Raising the level of abstraction, however, rarely\ncomes free - a performance penalty is possible. How good, then, are current\nmachine learning clouds on real-world machine learning workloads?\n  We study this question with a focus on binary classication problems. We\npresent mlbench, a novel benchmark constructed by harvesting datasets from\nKaggle competitions. We then compare the performance of the top winning code\navailable from Kaggle with that of running machine learning clouds from both\nAzure and Amazon on mlbench. Our comparative study reveals the strength and\nweakness of existing machine learning clouds and points out potential future\ndirections for improvement.",
    "pdf_link": "http://arxiv.org/pdf/1707.09562v3.pdf",
    "authors": [
      "Yu Liu",
      "Hantian Zhang",
      "Luyuan Zeng",
      "Wentao Wu",
      "Ce Zhang"
    ]
  },
  {
    "title": "Data Pricing in Machine Learning Pipelines",
    "text": "Data Pricing in Machine Learning Pipelines. Machine learning is disruptive. At the same time, machine learning can only\nsucceed by collaboration among many parties in multiple steps naturally as\npipelines in an eco-system, such as collecting data for possible machine\nlearning applications, collaboratively training models by multiple parties and\ndelivering machine learning services to end users. Data is critical and\npenetrating in the whole machine learning pipelines. As machine learning\npipelines involve many parties and, in order to be successful, have to form a\nconstructive and dynamic eco-system, marketplaces and data pricing are\nfundamental in connecting and facilitating those many parties. In this article,\nwe survey the principles and the latest research development of data pricing in\nmachine learning pipelines. We start with a brief review of data marketplaces\nand pricing desiderata. Then, we focus on pricing in three important steps in\nmachine learning pipelines. To understand pricing in the step of training data\ncollection, we review pricing raw data sets and data labels. We also\ninvestigate pricing in the step of collaborative training of machine learning\nmodels, and overview pricing machine learning models for end users in the step\nof machine learning deployment. We also discuss a series of possible future\ndirections.",
    "pdf_link": "http://arxiv.org/pdf/2108.07915v1.pdf",
    "authors": [
      "Zicun Cong",
      "Xuan Luo",
      "Pei Jian",
      "Feida Zhu",
      "Yong Zhang"
    ]
  },
  {
    "title": "Techniques for Automated Machine Learning",
    "text": "Techniques for Automated Machine Learning. Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.",
    "pdf_link": "http://arxiv.org/pdf/1907.08908v1.pdf",
    "authors": [
      "Yi-Wei Chen",
      "Qingquan Song",
      "Xia Hu"
    ]
  },
  {
    "title": "The Landscape of Modern Machine Learning: A Review of Machine,\n  Distributed and Federated Learning",
    "text": "The Landscape of Modern Machine Learning: A Review of Machine,\n  Distributed and Federated Learning. With the advance of the powerful heterogeneous, parallel and distributed\ncomputing systems and ever increasing immense amount of data, machine learning\nhas become an indispensable part of cutting-edge technology, scientific\nresearch and consumer products. In this study, we present a review of modern\nmachine and deep learning. We provide a high-level overview for the latest\nadvanced machine learning algorithms, applications, and frameworks. Our\ndiscussion encompasses parallel distributed learning, deep learning as well as\nfederated learning. As a result, our work serves as an introductory text to the\nvast field of modern machine learning.",
    "pdf_link": "http://arxiv.org/pdf/2312.03120v1.pdf",
    "authors": [
      "Omer Subasi",
      "Oceane Bel",
      "Joseph Manzano",
      "Kevin Barker"
    ]
  },
  {
    "title": "Parallelization of Machine Learning Algorithms Respectively on Single\n  Machine and Spark",
    "text": "Parallelization of Machine Learning Algorithms Respectively on Single\n  Machine and Spark. With the rapid development of big data technologies, how to dig out useful\ninformation from massive data becomes an essential problem. However, using\nmachine learning algorithms to analyze large data may be time-consuming and\ninefficient on the traditional single machine. To solve these problems, this\npaper has made some research on the parallelization of several classic machine\nlearning algorithms respectively on the single machine and the big data\nplatform Spark. We compare the runtime and efficiency of traditional machine\nlearning algorithms with parallelized machine learning algorithms respectively\non the single machine and Spark platform. The research results have shown\nsignificant improvement in runtime and efficiency of parallelized machine\nlearning algorithms.",
    "pdf_link": "http://arxiv.org/pdf/2206.07090v2.pdf",
    "authors": [
      "Jiajun Shen"
    ]
  },
  {
    "title": "AutoCompete: A Framework for Machine Learning Competition",
    "text": "AutoCompete: A Framework for Machine Learning Competition. In this paper, we propose AutoCompete, a highly automated machine learning\nframework for tackling machine learning competitions. This framework has been\nlearned by us, validated and improved over a period of more than two years by\nparticipating in online machine learning competitions. It aims at minimizing\nhuman interference required to build a first useful predictive model and to\nassess the practical difficulty of a given machine learning challenge. The\nproposed system helps in identifying data types, choosing a machine learn- ing\nmodel, tuning hyper-parameters, avoiding over-fitting and optimization for a\nprovided evaluation metric. We also observe that the proposed system produces\nbetter (or comparable) results with less runtime as compared to other\napproaches.",
    "pdf_link": "http://arxiv.org/pdf/1507.02188v1.pdf",
    "authors": [
      "Abhishek Thakur",
      "Artus Krohn-Grimberghe"
    ]
  },
  {
    "title": "Joint Training of Deep Boltzmann Machines",
    "text": "Joint Training of Deep Boltzmann Machines. We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods require an initial learning pass that trains the deep Boltzmann machine\ngreedily, one layer at a time, or do not perform well on classifi- cation\ntasks.",
    "pdf_link": "http://arxiv.org/pdf/1212.2686v1.pdf",
    "authors": [
      "Ian Goodfellow",
      "Aaron Courville",
      "Yoshua Bengio"
    ]
  },
  {
    "title": "Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in\n  Social Good Applications",
    "text": "Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in\n  Social Good Applications. This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning\nin Social Good Applications, which was held on June 24, 2016 in New York.",
    "pdf_link": "http://arxiv.org/pdf/1607.02450v2.pdf",
    "authors": [
      "Kush R. Varshney"
    ]
  },
  {
    "title": "Mathematical Perspective of Machine Learning",
    "text": "Mathematical Perspective of Machine Learning. We take a closer look at some theoretical challenges of Machine Learning as a\nfunction approximation, gradient descent as the default optimization algorithm,\nlimitations of fixed length and width networks and a different approach to RNNs\nfrom a mathematical perspective.",
    "pdf_link": "http://arxiv.org/pdf/2007.01503v1.pdf",
    "authors": [
      "Yarema Boryshchak"
    ]
  },
  {
    "title": "Private Machine Learning via Randomised Response",
    "text": "Private Machine Learning via Randomised Response. We introduce a general learning framework for private machine learning based\non randomised response. Our assumption is that all actors are potentially\nadversarial and as such we trust only to release a single noisy version of an\nindividual's datapoint. We discuss a general approach that forms a consistent\nway to estimate the true underlying machine learning model and demonstrate this\nin the case of logistic regression.",
    "pdf_link": "http://arxiv.org/pdf/2001.04942v2.pdf",
    "authors": [
      "David Barber"
    ]
  },
  {
    "title": "Ten-year Survival Prediction for Breast Cancer Patients",
    "text": "Ten-year Survival Prediction for Breast Cancer Patients. This report assesses different machine learning approaches to 10-year\nsurvival prediction of breast cancer patients.",
    "pdf_link": "http://arxiv.org/pdf/1911.00776v1.pdf",
    "authors": [
      "Changmao Li",
      "Han He",
      "Yunze Hao",
      "Caleb Ziems"
    ]
  },
  {
    "title": "A Survey of Optimization Methods from a Machine Learning Perspective",
    "text": "A Survey of Optimization Methods from a Machine Learning Perspective. Machine learning develops rapidly, which has made many theoretical\nbreakthroughs and is widely applied in various fields. Optimization, as an\nimportant part of machine learning, has attracted much attention of\nresearchers. With the exponential growth of data amount and the increase of\nmodel complexity, optimization methods in machine learning face more and more\nchallenges. A lot of work on solving optimization problems or improving\noptimization methods in machine learning has been proposed successively. The\nsystematic retrospect and summary of the optimization methods from the\nperspective of machine learning are of great significance, which can offer\nguidance for both developments of optimization and machine learning research.\nIn this paper, we first describe the optimization problems in machine learning.\nThen, we introduce the principles and progresses of commonly used optimization\nmethods. Next, we summarize the applications and developments of optimization\nmethods in some popular machine learning fields. Finally, we explore and give\nsome challenges and open problems for the optimization in machine learning.",
    "pdf_link": "http://arxiv.org/pdf/1906.06821v2.pdf",
    "authors": [
      "Shiliang Sun",
      "Zehui Cao",
      "Han Zhu",
      "Jing Zhao"
    ]
  },
  {
    "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
    "text": "When Machine Learning Meets Privacy: A Survey and Outlook. The newly emerged machine learning (e.g. deep learning) methods have become a\nstrong driving force to revolutionize a wide range of industries, such as smart\nhealthcare, financial technology, and surveillance systems. Meanwhile, privacy\nhas emerged as a big concern in this machine learning-based artificial\nintelligence era. It is important to note that the problem of privacy\npreservation in the context of machine learning is quite different from that in\ntraditional data privacy protection, as machine learning can act as both friend\nand foe. Currently, the work on the preservation of privacy and machine\nlearning (ML) is still in an infancy stage, as most existing solutions only\nfocus on privacy problems during the machine learning process. Therefore, a\ncomprehensive study on the privacy preservation problems and machine learning\nis required. This paper surveys the state of the art in privacy issues and\nsolutions for machine learning. The survey covers three categories of\ninteractions between privacy and machine learning: (i) private machine\nlearning, (ii) machine learning aided privacy protection, and (iii) machine\nlearning-based privacy attack and corresponding protection schemes. The current\nresearch progress in each category is reviewed and the key challenges are\nidentified. Finally, based on our in-depth analysis of the area of privacy and\nmachine learning, we point out future research directions in this field.",
    "pdf_link": "http://arxiv.org/pdf/2011.11819v1.pdf",
    "authors": [
      "Bo Liu",
      "Ming Ding",
      "Sina Shaham",
      "Wenny Rahayu",
      "Farhad Farokhi",
      "Zihuai Lin"
    ]
  },
  {
    "title": "Augmented Q Imitation Learning (AQIL)",
    "text": "Augmented Q Imitation Learning (AQIL). The study of unsupervised learning can be generally divided into two\ncategories: imitation learning and reinforcement learning. In imitation\nlearning the machine learns by mimicking the behavior of an expert system\nwhereas in reinforcement learning the machine learns via direct environment\nfeedback. Traditional deep reinforcement learning takes a significant time\nbefore the machine starts to converge to an optimal policy. This paper proposes\nAugmented Q-Imitation-Learning, a method by which deep reinforcement learning\nconvergence can be accelerated by applying Q-imitation-learning as the initial\ntraining process in traditional Deep Q-learning.",
    "pdf_link": "http://arxiv.org/pdf/2004.00993v2.pdf",
    "authors": [
      "Xiao Lei Zhang",
      "Anish Agarwal"
    ]
  },
  {
    "title": "Probabilistic Machine Learning for Healthcare",
    "text": "Probabilistic Machine Learning for Healthcare. Machine learning can be used to make sense of healthcare data. Probabilistic\nmachine learning models help provide a complete picture of observed data in\nhealthcare. In this review, we examine how probabilistic machine learning can\nadvance healthcare. We consider challenges in the predictive model building\npipeline where probabilistic models can be beneficial including calibration and\nmissing data. Beyond predictive models, we also investigate the utility of\nprobabilistic machine learning models in phenotyping, in generative models for\nclinical use cases, and in reinforcement learning.",
    "pdf_link": "http://arxiv.org/pdf/2009.11087v1.pdf",
    "authors": [
      "Irene Y. Chen",
      "Shalmali Joshi",
      "Marzyeh Ghassemi",
      "Rajesh Ranganath"
    ]
  },
  {
    "title": "Evaluation Challenges for Geospatial ML",
    "text": "Evaluation Challenges for Geospatial ML. As geospatial machine learning models and maps derived from their predictions\nare increasingly used for downstream analyses in science and policy, it is\nimperative to evaluate their accuracy and applicability. Geospatial machine\nlearning has key distinctions from other learning paradigms, and as such, the\ncorrect way to measure performance of spatial machine learning outputs has been\na topic of debate. In this paper, I delineate unique challenges of model\nevaluation for geospatial machine learning with global or remotely sensed\ndatasets, culminating in concrete takeaways to improve evaluations of\ngeospatial model performance.",
    "pdf_link": "http://arxiv.org/pdf/2303.18087v1.pdf",
    "authors": [
      "Esther Rolf"
    ]
  },
  {
    "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault\n  Tolerance",
    "text": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault\n  Tolerance. Quantum machine learning, which involves running machine learning algorithms\non quantum devices, has garnered significant attention in both academic and\nbusiness circles. In this paper, we offer a comprehensive and unbiased review\nof the various concepts that have emerged in the field of quantum machine\nlearning. This includes techniques used in Noisy Intermediate-Scale Quantum\n(NISQ) technologies and approaches for algorithms compatible with\nfault-tolerant quantum computing hardware. Our review covers fundamental\nconcepts, algorithms, and the statistical learning theory pertinent to quantum\nmachine learning.",
    "pdf_link": "http://arxiv.org/pdf/2401.11351v2.pdf",
    "authors": [
      "Yunfei Wang",
      "Junyu Liu"
    ]
  },
  {
    "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality\n  Assurance Methodology",
    "text": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality\n  Assurance Methodology. Machine learning is an established and frequently used technique in industry\nand academia but a standard process model to improve success and efficiency of\nmachine learning applications is still missing. Project organizations and\nmachine learning practitioners have a need for guidance throughout the life\ncycle of a machine learning application to meet business expectations. We\ntherefore propose a process model for the development of machine learning\napplications, that covers six phases from defining the scope to maintaining the\ndeployed machine learning application. The first phase combines business and\ndata understanding as data availability oftentimes affects the feasibility of\nthe project. The sixth phase covers state-of-the-art approaches for monitoring\nand maintenance of a machine learning applications, as the risk of model\ndegradation in a changing environment is eminent. With each task of the\nprocess, we propose quality assurance methodology that is suitable to adress\nchallenges in machine learning development that we identify in form of risks.\nThe methodology is drawn from practical experience and scientific literature\nand has proven to be general and stable. The process model expands on CRISP-DM,\na data mining process model that enjoys strong industry support but lacks to\naddress machine learning specific tasks. Our work proposes an industry and\napplication neutral process model tailored for machine learning applications\nwith focus on technical tasks for quality assurance.",
    "pdf_link": "http://arxiv.org/pdf/2003.05155v2.pdf",
    "authors": [
      "Stefan Studer",
      "Thanh Binh Bui",
      "Christian Drescher",
      "Alexander Hanuschkin",
      "Ludwig Winkler",
      "Steven Peters",
      "Klaus-Robert Mueller"
    ]
  },
  {
    "title": "Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of\n  learning relational order via reinforcement learning procedure?",
    "text": "Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of\n  learning relational order via reinforcement learning procedure?. In this article, we extend the conventional framework of\nconvolutional-Restricted-Boltzmann-Machine to learn highly abstract features\namong abitrary number of time related input maps by constructing a layer of\nmultiplicative units, which capture the relations among inputs. In many cases,\nmore than two maps are strongly related, so it is wise to make multiplicative\nunit learn relations among more input maps, in other words, to find the optimal\nrelational-order of each unit. In order to enable our machine to learn\nrelational order, we developed a reinforcement-learning method whose optimality\nis proven to train the network.",
    "pdf_link": "http://arxiv.org/pdf/1706.08001v1.pdf",
    "authors": [
      "Zizhuang Wang"
    ]
  },
  {
    "title": "Machine Learning Potential Repository",
    "text": "Machine Learning Potential Repository. This paper introduces a machine learning potential repository that includes\nPareto optimal machine learning potentials. It also shows the systematic\ndevelopment of accurate and fast machine learning potentials for a wide range\nof elemental systems. As a result, many Pareto optimal machine learning\npotentials are available in the repository from a website. Therefore, the\nrepository will help many scientists to perform accurate and fast atomistic\nsimulations.",
    "pdf_link": "http://arxiv.org/pdf/2007.14206v1.pdf",
    "authors": [
      "Atsuto Seko"
    ]
  },
  {
    "title": "Quantum memristors for neuromorphic quantum machine learning",
    "text": "Quantum memristors for neuromorphic quantum machine learning. Quantum machine learning may permit to realize more efficient machine\nlearning calculations with near-term quantum devices. Among the diverse quantum\nmachine learning paradigms which are currently being considered, quantum\nmemristors are promising as a way of combining, in the same quantum hardware, a\nunitary evolution with the nonlinearity provided by the measurement and\nfeedforward. Thus, an efficient way of deploying neuromorphic quantum computing\nfor quantum machine learning may be enabled.",
    "pdf_link": "http://arxiv.org/pdf/2412.18979v1.pdf",
    "authors": [
      "Lucas Lamata"
    ]
  },
  {
    "title": "metric-learn: Metric Learning Algorithms in Python",
    "text": "metric-learn: Metric Learning Algorithms in Python. metric-learn is an open source Python package implementing supervised and\nweakly-supervised distance metric learning algorithms. As part of\nscikit-learn-contrib, it provides a unified interface compatible with\nscikit-learn which allows to easily perform cross-validation, model selection,\nand pipelining with other machine learning estimators. metric-learn is\nthoroughly tested and available on PyPi under the MIT licence.",
    "pdf_link": "http://arxiv.org/pdf/1908.04710v3.pdf",
    "authors": [
      "William de Vazelhes",
      "CJ Carey",
      "Yuan Tang",
      "Nathalie Vauquier",
      "Aur\u00e9lien Bellet"
    ]
  },
  {
    "title": "Theoretical Models of Learning to Learn",
    "text": "Theoretical Models of Learning to Learn. A Machine can only learn if it is biased in some way. Typically the bias is\nsupplied by hand, for example through the choice of an appropriate set of\nfeatures. However, if the learning machine is embedded within an {\\em\nenvironment} of related tasks, then it can {\\em learn} its own bias by learning\nsufficiently many tasks from the environment. In this paper two models of bias\nlearning (or equivalently, learning to learn) are introduced and the main\ntheoretical results presented. The first model is a PAC-type model based on\nempirical process theory, while the second is a hierarchical Bayes model.",
    "pdf_link": "http://arxiv.org/pdf/2002.12364v1.pdf",
    "authors": [
      "Jonathan Baxter"
    ]
  },
  {
    "title": "On-the-Fly Learning in a Perpetual Learning Machine",
    "text": "On-the-Fly Learning in a Perpetual Learning Machine. Despite the promise of brain-inspired machine learning, deep neural networks\n(DNN) have frustratingly failed to bridge the deceptively large gap between\nlearning and memory. Here, we introduce a Perpetual Learning Machine; a new\ntype of DNN that is capable of brain-like dynamic 'on the fly' learning because\nit exists in a self-supervised state of Perpetual Stochastic Gradient Descent.\nThus, we provide the means to unify learning and memory within a machine\nlearning framework. We also explore the elegant duality of abstraction and\nsynthesis: the Yin and Yang of deep learning.",
    "pdf_link": "http://arxiv.org/pdf/1509.00913v3.pdf",
    "authors": [
      "Andrew J. R. Simpson"
    ]
  },
  {
    "title": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality\n  in Machine Learning",
    "text": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality\n  in Machine Learning. We propose a clustering-based iterative algorithm to solve certain\noptimization problems in machine learning, where we start the algorithm by\naggregating the original data, solving the problem on aggregated data, and then\nin subsequent steps gradually disaggregate the aggregated data. We apply the\nalgorithm to common machine learning problems such as the least absolute\ndeviation regression problem, support vector machines, and semi-supervised\nsupport vector machines. We derive model-specific data aggregation and\ndisaggregation procedures. We also show optimality, convergence, and the\noptimality gap of the approximated solution in each iteration. A computational\nstudy is provided.",
    "pdf_link": "http://arxiv.org/pdf/1607.01400v1.pdf",
    "authors": [
      "Young Woong Park",
      "Diego Klabjan"
    ]
  },
  {
    "title": "Human-in-the-loop Machine Learning: A Macro-Micro Perspective",
    "text": "Human-in-the-loop Machine Learning: A Macro-Micro Perspective. Though technical advance of artificial intelligence and machine learning has\nenabled many promising intelligent systems, many computing tasks are still not\nable to be fully accomplished by machine intelligence. Motivated by the\ncomplementary nature of human and machine intelligence, an emerging trend is to\ninvolve humans in the loop of machine learning and decision-making. In this\npaper, we provide a macro-micro review of human-in-the-loop machine learning.\nWe first describe major machine learning challenges which can be addressed by\nhuman intervention in the loop. Then we examine closely the latest research and\nfindings of introducing humans into each step of the lifecycle of machine\nlearning. Finally, we analyze current research gaps and point out future\nresearch directions.",
    "pdf_link": "http://arxiv.org/pdf/2202.10564v1.pdf",
    "authors": [
      "Jiangtao Wang",
      "Bin Guo",
      "Liming Chen"
    ]
  },
  {
    "title": "Can Machines Learn the True Probabilities?",
    "text": "Can Machines Learn the True Probabilities?. When there exists uncertainty, AI machines are designed to make decisions so\nas to reach the best expected outcomes. Expectations are based on true facts\nabout the objective environment the machines interact with, and those facts can\nbe encoded into AI models in the form of true objective probability functions.\nAccordingly, AI models involve probabilistic machine learning in which the\nprobabilities should be objectively interpreted. We prove under some basic\nassumptions when machines can learn the true objective probabilities, if any,\nand when machines cannot learn them.",
    "pdf_link": "http://arxiv.org/pdf/2407.05526v1.pdf",
    "authors": [
      "Jinsook Kim"
    ]
  },
  {
    "title": "Scientific Machine Learning Benchmarks",
    "text": "Scientific Machine Learning Benchmarks. The breakthrough in Deep Learning neural networks has transformed the use of\nAI and machine learning technologies for the analysis of very large\nexperimental datasets. These datasets are typically generated by large-scale\nexperimental facilities at national laboratories. In the context of science,\nscientific machine learning focuses on training machines to identify patterns,\ntrends, and anomalies to extract meaningful scientific insights from such\ndatasets. With a new generation of experimental facilities, the rate of data\ngeneration and the scale of data volumes will increasingly require the use of\nmore automated data analysis. At present, identifying the most appropriate\nmachine learning algorithm for the analysis of any given scientific dataset is\nstill a challenge for scientists. This is due to many different machine\nlearning frameworks, computer architectures, and machine learning models.\nHistorically, for modelling and simulation on HPC systems such problems have\nbeen addressed through benchmarking computer applications, algorithms, and\narchitectures. Extending such a benchmarking approach and identifying metrics\nfor the application of machine learning methods to scientific datasets is a new\nchallenge for both scientists and computer scientists. In this paper, we\ndescribe our approach to the development of scientific machine learning\nbenchmarks and review other approaches to benchmarking scientific machine\nlearning.",
    "pdf_link": "http://arxiv.org/pdf/2110.12773v1.pdf",
    "authors": [
      "Jeyan Thiyagalingam",
      "Mallikarjun Shankar",
      "Geoffrey Fox",
      "Tony Hey"
    ]
  },
  {
    "title": "Some Insights into Lifelong Reinforcement Learning Systems",
    "text": "Some Insights into Lifelong Reinforcement Learning Systems. A lifelong reinforcement learning system is a learning system that has the\nability to learn through trail-and-error interaction with the environment over\nits lifetime. In this paper, I give some arguments to show that the traditional\nreinforcement learning paradigm fails to model this type of learning system.\nSome insights into lifelong reinforcement learning are provided, along with a\nsimplistic prototype lifelong reinforcement learning system.",
    "pdf_link": "http://arxiv.org/pdf/2001.09608v1.pdf",
    "authors": [
      "Changjian Li"
    ]
  },
  {
    "title": "Towards A Rigorous Science of Interpretable Machine Learning",
    "text": "Towards A Rigorous Science of Interpretable Machine Learning. As machine learning systems become ubiquitous, there has been a surge of\ninterest in interpretable machine learning: systems that provide explanation\nfor their outputs. These explanations are often used to qualitatively assess\nother criteria such as safety or non-discrimination. However, despite the\ninterest in interpretability, there is very little consensus on what\ninterpretable machine learning is and how it should be measured. In this\nposition paper, we first define interpretability and describe when\ninterpretability is needed (and when it is not). Next, we suggest a taxonomy\nfor rigorous evaluation and expose open questions towards a more rigorous\nscience of interpretable machine learning.",
    "pdf_link": "http://arxiv.org/pdf/1702.08608v2.pdf",
    "authors": [
      "Finale Doshi-Velez",
      "Been Kim"
    ]
  },
  {
    "title": "Infrastructure for Usable Machine Learning: The Stanford DAWN Project",
    "text": "Infrastructure for Usable Machine Learning: The Stanford DAWN Project. Despite incredible recent advances in machine learning, building machine\nlearning applications remains prohibitively time-consuming and expensive for\nall but the best-trained, best-funded engineering organizations. This expense\ncomes not from a need for new and improved statistical models but instead from\na lack of systems and tools for supporting end-to-end machine learning\napplication development, from data preparation and labeling to\nproductionization and monitoring. In this document, we outline opportunities\nfor infrastructure supporting usable, end-to-end machine learning applications\nin the context of the nascent DAWN (Data Analytics for What's Next) project at\nStanford.",
    "pdf_link": "http://arxiv.org/pdf/1705.07538v2.pdf",
    "authors": [
      "Peter Bailis",
      "Kunle Olukotun",
      "Christopher Re",
      "Matei Zaharia"
    ]
  },
  {
    "title": "Solving machine learning optimization problems using quantum computers",
    "text": "Solving machine learning optimization problems using quantum computers. Classical optimization algorithms in machine learning often take a long time\nto compute when applied to a multi-dimensional problem and require a huge\namount of CPU and GPU resource. Quantum parallelism has a potential to speed up\nmachine learning algorithms. We describe a generic mathematical model to\nleverage quantum parallelism to speed-up machine learning algorithms. We also\napply quantum machine learning and quantum parallelism applied to a\n$3$-dimensional image that vary with time.",
    "pdf_link": "http://arxiv.org/pdf/1911.08587v1.pdf",
    "authors": [
      "Venkat R. Dasari",
      "Mee Seong Im",
      "Lubjana Beshaj"
    ]
  },
  {
    "title": "Bayesian Optimization for Machine Learning : A Practical Guidebook",
    "text": "Bayesian Optimization for Machine Learning : A Practical Guidebook. The engineering of machine learning systems is still a nascent field; relying\non a seemingly daunting collection of quickly evolving tools and best\npractices. It is our hope that this guidebook will serve as a useful resource\nfor machine learning practitioners looking to take advantage of Bayesian\noptimization techniques. We outline four example machine learning problems that\ncan be solved using open source machine learning libraries, and highlight the\nbenefits of using Bayesian optimization in the context of these common machine\nlearning applications.",
    "pdf_link": "http://arxiv.org/pdf/1612.04858v1.pdf",
    "authors": [
      "Ian Dewancker",
      "Michael McCourt",
      "Scott Clark"
    ]
  },
  {
    "title": "Techniques for Interpretable Machine Learning",
    "text": "Techniques for Interpretable Machine Learning. Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.",
    "pdf_link": "http://arxiv.org/pdf/1808.00033v3.pdf",
    "authors": [
      "Mengnan Du",
      "Ninghao Liu",
      "Xia Hu"
    ]
  },
  {
    "title": "Lale: Consistent Automated Machine Learning",
    "text": "Lale: Consistent Automated Machine Learning. Automated machine learning makes it easier for data scientists to develop\npipelines by searching over possible choices for hyperparameters, algorithms,\nand even pipeline topologies. Unfortunately, the syntax for automated machine\nlearning tools is inconsistent with manual machine learning, with each other,\nand with error checks. Furthermore, few tools support advanced features such as\ntopology search or higher-order operators. This paper introduces Lale, a\nlibrary of high-level Python interfaces that simplifies and unifies automated\nmachine learning in a consistent way.",
    "pdf_link": "http://arxiv.org/pdf/2007.01977v1.pdf",
    "authors": [
      "Guillaume Baudart",
      "Martin Hirzel",
      "Kiran Kate",
      "Parikshit Ram",
      "Avraham Shinnar"
    ]
  },
  {
    "title": "Differential Replication in Machine Learning",
    "text": "Differential Replication in Machine Learning. When deployed in the wild, machine learning models are usually confronted\nwith data and requirements that constantly vary, either because of changes in\nthe generating distribution or because external constraints change the\nenvironment where the model operates. To survive in such an ecosystem, machine\nlearning models need to adapt to new conditions by evolving over time. The idea\nof model adaptability has been studied from different perspectives. In this\npaper, we propose a solution based on reusing the knowledge acquired by the\nalready deployed machine learning models and leveraging it to train future\ngenerations. This is the idea behind differential replication of machine\nlearning models.",
    "pdf_link": "http://arxiv.org/pdf/2007.07981v1.pdf",
    "authors": [
      "Irene Unceta",
      "Jordi Nin",
      "Oriol Pujol"
    ]
  },
  {
    "title": "mlr3proba: An R Package for Machine Learning in Survival Analysis",
    "text": "mlr3proba: An R Package for Machine Learning in Survival Analysis. As machine learning has become increasingly popular over the last few\ndecades, so too has the number of machine learning interfaces for implementing\nthese models. Whilst many R libraries exist for machine learning, very few\noffer extended support for survival analysis. This is problematic considering\nits importance in fields like medicine, bioinformatics, economics, engineering,\nand more. mlr3proba provides a comprehensive machine learning interface for\nsurvival analysis and connects with mlr3's general model tuning and\nbenchmarking facilities to provide a systematic infrastructure for survival\nmodeling and evaluation.",
    "pdf_link": "http://arxiv.org/pdf/2008.08080v2.pdf",
    "authors": [
      "Raphael Sonabend",
      "Franz J. Kir\u00e1ly",
      "Andreas Bender",
      "Bernd Bischl",
      "Michel Lang"
    ]
  },
  {
    "title": "Teaching Uncertainty Quantification in Machine Learning through Use\n  Cases",
    "text": "Teaching Uncertainty Quantification in Machine Learning through Use\n  Cases. Uncertainty in machine learning is not generally taught as general knowledge\nin Machine Learning course curricula. In this paper we propose a short\ncurriculum for a course about uncertainty in machine learning, and complement\nthe course with a selection of use cases, aimed to trigger discussion and let\nstudents play with the concepts of uncertainty in a programming setting. Our\nuse cases cover the concept of output uncertainty, Bayesian neural networks and\nweight distributions, sources of uncertainty, and out of distribution\ndetection. We expect that this curriculum and set of use cases motivates the\ncommunity to adopt these important concepts into courses for safety in AI.",
    "pdf_link": "http://arxiv.org/pdf/2108.08712v1.pdf",
    "authors": [
      "Matias Valdenegro-Toro"
    ]
  },
  {
    "title": "Introduction to Machine Learning for Physicians: A Survival Guide for\n  Data Deluge",
    "text": "Introduction to Machine Learning for Physicians: A Survival Guide for\n  Data Deluge. Many modern research fields increasingly rely on collecting and analysing\nmassive, often unstructured, and unwieldy datasets. Consequently, there is\ngrowing interest in machine learning and artificial intelligence applications\nthat can harness this `data deluge'. This broad nontechnical overview provides\na gentle introduction to machine learning with a specific focus on medical and\nbiological applications. We explain the common types of machine learning\nalgorithms and typical tasks that can be solved, illustrating the basics with\nconcrete examples from healthcare. Lastly, we provide an outlook on open\nchallenges, limitations, and potential impacts of machine-learning-powered\nmedicine.",
    "pdf_link": "http://arxiv.org/pdf/2212.12303v1.pdf",
    "authors": [
      "Ri\u010dards Marcinkevi\u010ds",
      "Ece Ozkan",
      "Julia E. Vogt"
    ]
  },
  {
    "title": "Machine learning-assisted close-set X-ray diffraction phase\n  identification of transition metals",
    "text": "Machine learning-assisted close-set X-ray diffraction phase\n  identification of transition metals. Machine learning has been applied to the problem of X-ray diffraction phase\nprediction with promising results. In this paper, we describe a method for\nusing machine learning to predict crystal structure phases from X-ray\ndiffraction data of transition metals and their oxides. We evaluate the\nperformance of our method and compare the variety of its settings. Our results\ndemonstrate that the proposed machine learning framework achieves competitive\nperformance. This demonstrates the potential for machine learning to\nsignificantly impact the field of X-ray diffraction and crystal structure\ndetermination. Open-source implementation:\nhttps://github.com/maxnygma/NeuralXRD.",
    "pdf_link": "http://arxiv.org/pdf/2305.15410v1.pdf",
    "authors": [
      "Maksim Zhdanov",
      "Andrey Zhdanov"
    ]
  },
  {
    "title": "Insights From Insurance for Fair Machine Learning",
    "text": "Insights From Insurance for Fair Machine Learning. We argue that insurance can act as an analogon for the social situatedness of\nmachine learning systems, hence allowing machine learning scholars to take\ninsights from the rich and interdisciplinary insurance literature. Tracing the\ninteraction of uncertainty, fairness and responsibility in insurance provides a\nfresh perspective on fairness in machine learning. We link insurance fairness\nconceptions to their machine learning relatives, and use this bridge to\nproblematize fairness as calibration. In this process, we bring to the\nforefront two themes that have been largely overlooked in the machine learning\nliterature: responsibility and aggregate-individual tensions.",
    "pdf_link": "http://arxiv.org/pdf/2306.14624v2.pdf",
    "authors": [
      "Christian Fr\u00f6hlich",
      "Robert C. Williamson"
    ]
  },
  {
    "title": "Quantum Dynamics of Machine Learning",
    "text": "Quantum Dynamics of Machine Learning. The quantum dynamic equation (QDE) of machine learning is obtained based on\nSchr\\\"odinger equation and potential energy equivalence relationship. Through\nWick rotation, the relationship between quantum dynamics and thermodynamics is\nalso established in this paper. This equation reformulates the iterative\nprocess of machine learning into a time-dependent partial differential equation\nwith a clear mathematical structure, offering a theoretical framework for\ninvestigating machine learning iterations through quantum and mathematical\ntheories. Within this framework, the fundamental iterative process, the\ndiffusion model, and the Softmax and Sigmoid functions are examined, validating\nthe proposed quantum dynamics equations. This approach not only presents a\nrigorous theoretical foundation for machine learning but also holds promise for\nsupporting the implementation of machine learning algorithms on quantum\ncomputers.",
    "pdf_link": "http://arxiv.org/pdf/2407.19890v1.pdf",
    "authors": [
      "Peng Wang",
      "Maimaitiniyazi Maimaitiabudula"
    ]
  },
  {
    "title": "On the Conditions for Domain Stability for Machine Learning: a\n  Mathematical Approach",
    "text": "On the Conditions for Domain Stability for Machine Learning: a\n  Mathematical Approach. This work proposes a mathematical approach that (re)defines a property of\nMachine Learning models named stability and determines sufficient conditions to\nvalidate it. Machine Learning models are represented as functions, and the\ncharacteristics in scope depend upon the domain of the function, what allows us\nto adopt topological and metric spaces theory as a basis. Finally, this work\nprovides some equivalences useful to prove and test stability in Machine\nLearning models. The results suggest that whenever stability is aligned with\nthe notion of function smoothness, then the stability of Machine Learning\nmodels primarily depends upon certain topological, measurable properties of the\nclassification sets within the ML model domain.",
    "pdf_link": "http://arxiv.org/pdf/2412.00464v1.pdf",
    "authors": [
      "Gabriel Pedroza"
    ]
  },
  {
    "title": "Distributed Multitask Learning",
    "text": "Distributed Multitask Learning. We consider the problem of distributed multi-task learning, where each\nmachine learns a separate, but related, task. Specifically, each machine learns\na linear predictor in high-dimensional space,where all tasks share the same\nsmall support. We present a communication-efficient estimator based on the\ndebiased lasso and show that it is comparable with the optimal centralized\nmethod.",
    "pdf_link": "http://arxiv.org/pdf/1510.00633v1.pdf",
    "authors": [
      "Jialei Wang",
      "Mladen Kolar",
      "Nathan Srebro"
    ]
  }
]